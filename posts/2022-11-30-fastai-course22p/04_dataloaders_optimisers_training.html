<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.2.269">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">

<meta name="author" content="John Richmond">

<title>John Richmond - Notebook to establish mini-batch training from first principles</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1.6em;
  vertical-align: middle;
}
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { color: #008000; } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { color: #008000; font-weight: bold; } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>


<script src="../../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../../site_libs/quarto-nav/headroom.min.js"></script>
<script src="../../site_libs/clipboard/clipboard.min.js"></script>
<script src="../../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../../site_libs/quarto-search/fuse.min.js"></script>
<script src="../../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../../">
<script src="../../site_libs/quarto-html/quarto.js"></script>
<script src="../../site_libs/quarto-html/popper.min.js"></script>
<script src="../../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../../site_libs/quarto-html/anchor.min.js"></script>
<link href="../../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../../site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" class="quarto-color-scheme" id="quarto-text-highlighting-styles">
<link href="../../site_libs/quarto-html/quarto-syntax-highlighting-dark.css" rel="prefetch" class="quarto-color-scheme quarto-color-alternate" id="quarto-text-highlighting-styles">
<script src="../../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../../site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" class="quarto-color-scheme" id="quarto-bootstrap" data-mode="light">
<link href="../../site_libs/bootstrap/bootstrap-dark.min.css" rel="prefetch" class="quarto-color-scheme quarto-color-alternate" id="quarto-bootstrap" data-mode="dark">
<script id="quarto-search-options" type="application/json">{
  "location": "navbar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "end",
  "type": "overlay",
  "limit": 20,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit"
  }
}</script>

  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

<link rel="stylesheet" href="../../styles.css">
<meta property="og:title" content="John Richmond - Notebook to establish mini-batch training from first principles">
<meta property="og:description" content="Notebook based upon the fastai course 22p, “Part 2 of Practical Deep Learning for Coders”. This notebook builds the capability for training a model in batches.">
<meta property="og:site-name" content="John Richmond">
<meta name="twitter:title" content="John Richmond - Notebook to establish mini-batch training from first principles">
<meta name="twitter:description" content="Notebook based upon the fastai course 22p, “Part 2 of Practical Deep Learning for Coders”. This notebook builds the capability for training a model in batches.">
<meta name="twitter:creator" content="@JohnWRichmond">
<meta name="twitter:card" content="summary_large_image">
</head>

<body class="nav-fixed">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
    <nav class="navbar navbar-expand-lg navbar-dark ">
      <div class="navbar-container container-fluid">
      <div class="navbar-brand-container">
    <a class="navbar-brand" href="../../index.html">
    <span class="navbar-title">John Richmond</span>
    </a>
  </div>
          <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarCollapse" aria-controls="navbarCollapse" aria-expanded="false" aria-label="Toggle navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
  <span class="navbar-toggler-icon"></span>
</button>
          <div class="collapse navbar-collapse" id="navbarCollapse">
            <ul class="navbar-nav navbar-nav-scroll me-auto">
  <li class="nav-item">
    <a class="nav-link" href="../../about.html">
 <span class="menu-text">About</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../../blog.html">
 <span class="menu-text">Blog</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../../articles.gmd">
 <span class="menu-text">Articles</span></a>
  </li>  
</ul>
            <ul class="navbar-nav navbar-nav-scroll ms-auto">
  <li class="nav-item compact">
    <a class="nav-link" href="https://github.com/fromLittleAcorns/"><i class="bi bi-github" role="img">
</i> 
 <span class="menu-text"></span></a>
  </li>  
  <li class="nav-item compact">
    <a class="nav-link" href="https://www.linkedin.com//"><i class="bi bi-linkedin" role="img">
</i> 
 <span class="menu-text"></span></a>
  </li>  
  <li class="nav-item compact">
    <a class="nav-link" href="https://twitter.com/johnWRichmond"><i class="bi bi-twitter" role="img">
</i> 
 <span class="menu-text"></span></a>
  </li>  
  <li class="nav-item compact">
    <a class="nav-link" href="mailto:confusedjohn46@gmail.com"><i class="bi bi-envelope" role="img">
</i> 
 <span class="menu-text"></span></a>
  </li>  
  <li class="nav-item compact">
    <a class="nav-link" href="../../blog.xml"><i class="bi bi-rss" role="img">
</i> 
 <span class="menu-text"></span></a>
  </li>  
</ul>
              <div class="quarto-toggle-container">
                  <a href="" class="quarto-color-scheme-toggle nav-link" onclick="window.quartoToggleColorScheme(); return false;" title="Toggle dark mode"><i class="bi"></i></a>
              </div>
              <div id="quarto-search" class="" title="Search"></div>
          </div> <!-- /navcollapse -->
      </div> <!-- /container-fluid -->
    </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article page-navbar">
<!-- sidebar -->
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">On this page</h2>
   
  <ul>
  <li><a href="#introduction" id="toc-introduction" class="nav-link active" data-scroll-target="#introduction">Introduction</a></li>
  <li><a href="#initial-setup" id="toc-initial-setup" class="nav-link" data-scroll-target="#initial-setup">Initial setup</a>
  <ul class="collapse">
  <li><a href="#data" id="toc-data" class="nav-link" data-scroll-target="#data">Data</a></li>
  </ul></li>
  <li><a href="#loss-function" id="toc-loss-function" class="nav-link" data-scroll-target="#loss-function">Loss Function</a></li>
  <li><a href="#development-of-a-training-loop" id="toc-development-of-a-training-loop" class="nav-link" data-scroll-target="#development-of-a-training-loop">Development of a training loop</a>
  <ul class="collapse">
  <li><a href="#a-simple-training-loop" id="toc-a-simple-training-loop" class="nav-link" data-scroll-target="#a-simple-training-loop">A simple training loop</a>
  <ul class="collapse">
  <li><a href="#calculate-accuracy" id="toc-calculate-accuracy" class="nav-link" data-scroll-target="#calculate-accuracy">Calculate Accuracy</a></li>
  </ul></li>
  <li><a href="#adding-parameters-and-optim" id="toc-adding-parameters-and-optim" class="nav-link" data-scroll-target="#adding-parameters-and-optim">Adding parameters and optim</a>
  <ul class="collapse">
  <li><a href="#parameters" id="toc-parameters" class="nav-link" data-scroll-target="#parameters">Parameters</a></li>
  <li><a href="#the-nn.sequential-class" id="toc-the-nn.sequential-class" class="nav-link" data-scroll-target="#the-nn.sequential-class">The nn.Sequential Class</a></li>
  <li><a href="#introducing-the-optimiser-class-optim" id="toc-introducing-the-optimiser-class-optim" class="nav-link" data-scroll-target="#introducing-the-optimiser-class-optim">Introducing the optimiser class Optim</a></li>
  <li><a href="#dataset-and-dataloader" id="toc-dataset-and-dataloader" class="nav-link" data-scroll-target="#dataset-and-dataloader">Dataset and DataLoader</a></li>
  </ul></li>
  <li><a href="#adding-in-different-sampling-methods" id="toc-adding-in-different-sampling-methods" class="nav-link" data-scroll-target="#adding-in-different-sampling-methods">Adding in different sampling methods</a>
  <ul class="collapse">
  <li><a href="#finally-create-a-full-dataloader-using-the-above-components" id="toc-finally-create-a-full-dataloader-using-the-above-components" class="nav-link" data-scroll-target="#finally-create-a-full-dataloader-using-the-above-components">Finally create a full dataloader using the above components</a></li>
  </ul></li>
  <li><a href="#multiprocesssing-dataloader" id="toc-multiprocesssing-dataloader" class="nav-link" data-scroll-target="#multiprocesssing-dataloader">Multiprocesssing DataLoader</a></li>
  <li><a href="#pytorch-dataloader" id="toc-pytorch-dataloader" class="nav-link" data-scroll-target="#pytorch-dataloader">Pytorch DataLoader</a></li>
  <li><a href="#validation" id="toc-validation" class="nav-link" data-scroll-target="#validation">Validation</a></li>
  </ul></li>
  </ul>
<div class="toc-actions"><div><i class="bi bi-github"></i></div><div class="action-links"><p><a href="https://github.dev/fromLittleAcorns/johnrichmond.github.io/blob/main/posts/2022-11-30-fastai-course22p/04_dataloaders_optimisers_training.ipynb" class="toc-action">Edit this page</a></p><p><a href="https://github.com/fromLittleAcorns/johnrichmond.github.io/issues/new" class="toc-action">Report an issue</a></p></div></div></nav>
    </div>
<!-- main -->
<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<h1 class="title">Notebook to establish mini-batch training from first principles</h1>
</div>



<div class="quarto-title-meta">

    <div>
    <div class="quarto-title-meta-heading">Author</div>
    <div class="quarto-title-meta-contents">
             <p>John Richmond </p>
          </div>
  </div>
    
  
    
  </div>
  

</header>

<section id="introduction" class="level1">
<h1>Introduction</h1>
<p>Notebook based upon the fastai course 22p, “Part 2 of Practical Deep Learning for Coders”. This notebook builds the capability for training a model in batches. As such it covers: * understanding managing and accessing model parameters * Cross entropy loss for classification * dataloaders, including samplers and multiprocessing * optimisers - implementation of SGD and how to implement using model parameters * setting up training loops with validation</p>
<div class="cell" data-execution_count="1">
<div class="sourceCode cell-code" id="cb1"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pickle,gzip,math,os,time,shutil,torch,matplotlib <span class="im">as</span> mpl,numpy <span class="im">as</span> np,matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> pathlib <span class="im">import</span> Path</span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> torch <span class="im">import</span> tensor,nn</span>
<span id="cb1-4"><a href="#cb1-4" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> torch.nn.functional <span class="im">as</span> F</span>
<span id="cb1-5"><a href="#cb1-5" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> fastcore.test <span class="im">import</span> test_close</span>
<span id="cb1-6"><a href="#cb1-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-7"><a href="#cb1-7" aria-hidden="true" tabindex="-1"></a>torch.set_printoptions(precision<span class="op">=</span><span class="dv">2</span>, linewidth<span class="op">=</span><span class="dv">140</span>, sci_mode<span class="op">=</span><span class="va">False</span>)</span>
<span id="cb1-8"><a href="#cb1-8" aria-hidden="true" tabindex="-1"></a>torch.manual_seed(<span class="dv">1</span>)</span>
<span id="cb1-9"><a href="#cb1-9" aria-hidden="true" tabindex="-1"></a>mpl.rcParams[<span class="st">'image.cmap'</span>] <span class="op">=</span> <span class="st">'gray'</span></span>
<span id="cb1-10"><a href="#cb1-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-11"><a href="#cb1-11" aria-hidden="true" tabindex="-1"></a>path_to_data <span class="op">=</span> Path(<span class="st">'/Users/johnrichmond/local_datasets'</span>) <span class="op">/</span> Path(<span class="st">'data'</span>)</span>
<span id="cb1-12"><a href="#cb1-12" aria-hidden="true" tabindex="-1"></a>path_to_data.mkdir(exist_ok<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb1-13"><a href="#cb1-13" aria-hidden="true" tabindex="-1"></a>path_gz <span class="op">=</span> path_to_data <span class="op">/</span> <span class="st">'mnist.pkg.gz'</span></span>
<span id="cb1-14"><a href="#cb1-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-15"><a href="#cb1-15" aria-hidden="true" tabindex="-1"></a><span class="cf">with</span> gzip.<span class="bu">open</span>(path_gz, <span class="st">'rb'</span>) <span class="im">as</span> f: ((x_train, y_train), (x_valid, y_valid), _) <span class="op">=</span> pickle.load(f, encoding<span class="op">=</span><span class="st">'latin-1'</span>)</span>
<span id="cb1-16"><a href="#cb1-16" aria-hidden="true" tabindex="-1"></a>x_train, y_train, x_valid, y_valid <span class="op">=</span> <span class="bu">map</span>(tensor, [x_train, y_train, x_valid, y_valid])</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</section>
<section id="initial-setup" class="level1">
<h1>Initial setup</h1>
<section id="data" class="level2">
<h2 class="anchored" data-anchor-id="data">Data</h2>
<p>As before use Mnist data with a single hidden layer of 50 neurons</p>
<div class="cell" data-execution_count="2">
<div class="sourceCode cell-code" id="cb2"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb2-1"><a href="#cb2-1" aria-hidden="true" tabindex="-1"></a>n,m <span class="op">=</span> x_train.shape</span>
<span id="cb2-2"><a href="#cb2-2" aria-hidden="true" tabindex="-1"></a>c <span class="op">=</span> y_train.<span class="bu">max</span>()<span class="op">+</span><span class="dv">1</span></span>
<span id="cb2-3"><a href="#cb2-3" aria-hidden="true" tabindex="-1"></a>nh <span class="op">=</span> <span class="dv">50</span></span>
<span id="cb2-4"><a href="#cb2-4" aria-hidden="true" tabindex="-1"></a>n, m, c</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="2">
<pre><code>(50000, 784, tensor(10))</code></pre>
</div>
</div>
<p>Create a simple model that inherits from the pytorch nn.Module class</p>
<div class="cell" data-execution_count="3">
<div class="sourceCode cell-code" id="cb4"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb4-1"><a href="#cb4-1" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> Model(nn.Module):</span>
<span id="cb4-2"><a href="#cb4-2" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>, n_in, nh, n_out):</span>
<span id="cb4-3"><a href="#cb4-3" aria-hidden="true" tabindex="-1"></a>        <span class="bu">super</span>().<span class="fu">__init__</span>()</span>
<span id="cb4-4"><a href="#cb4-4" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.layers <span class="op">=</span> [nn.Linear(n_in,nh), nn.ReLU(), nn.Linear(nh,n_out)]</span>
<span id="cb4-5"><a href="#cb4-5" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb4-6"><a href="#cb4-6" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__call__</span>(<span class="va">self</span>, x):</span>
<span id="cb4-7"><a href="#cb4-7" aria-hidden="true" tabindex="-1"></a>        <span class="cf">for</span> l <span class="kw">in</span> <span class="va">self</span>.layers: x <span class="op">=</span> l(x)</span>
<span id="cb4-8"><a href="#cb4-8" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> x</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Pass the training data though the model and store the predictions. Check the shape of the output and also what the range of the preds is</p>
<div class="cell" data-execution_count="4">
<div class="sourceCode cell-code" id="cb5"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb5-1"><a href="#cb5-1" aria-hidden="true" tabindex="-1"></a>model <span class="op">=</span> Model(n_in<span class="op">=</span>m, nh<span class="op">=</span>nh, n_out<span class="op">=</span>c)</span>
<span id="cb5-2"><a href="#cb5-2" aria-hidden="true" tabindex="-1"></a>preds <span class="op">=</span> model(x_train.clone())</span>
<span id="cb5-3"><a href="#cb5-3" aria-hidden="true" tabindex="-1"></a>preds.shape, preds.<span class="bu">min</span>(), preds.<span class="bu">max</span>()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="4">
<pre><code>(torch.Size([50000, 10]),
 tensor(-0.35, grad_fn=&lt;MinBackward1&gt;),
 tensor(0.42, grad_fn=&lt;MaxBackward1&gt;))</code></pre>
</div>
</div>
</section>
</section>
<section id="loss-function" class="level1">
<h1>Loss Function</h1>
<p>In the previous notebook a very simple loss function was used. This will now be replaced with a cross entropy loss. There are several “tricks” that are used to take what is basically a relatively simple concept and implement it in a robust and efficient fashion. These will be explained.</p>
<p><span class="math display">\[\hbox{softmax(x)}_{i} = \frac{e^{x{_i}}}{e^{x{_1}}+e^{x{_2}} + \cdots + e^{x{_n}}}\]</span></p>
<p>Or:</p>
<p><span class="math display">\[\hbox{softmax(x)}_{i} = \frac{e^{x_{i}}}{\sum\limits_{0 \leq j &lt; n}{e^{x_{j}}}}\]</span></p>
<div class="cell" data-execution_count="113">
<div class="sourceCode cell-code" id="cb7"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb7-1"><a href="#cb7-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Note that this relies upon broadcasting the sum along axis 1 to make the divide work</span></span>
<span id="cb7-2"><a href="#cb7-2" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> log_softmax(x): <span class="cf">return</span> (x.exp() <span class="op">/</span> (x.exp().<span class="bu">sum</span>(axis<span class="op">=-</span><span class="dv">1</span>, keepdim<span class="op">=</span><span class="va">True</span>))).log()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell" data-execution_count="6">
<div class="sourceCode cell-code" id="cb8"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb8-1"><a href="#cb8-1" aria-hidden="true" tabindex="-1"></a>log_softmax(preds)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="6">
<pre><code>tensor([[-2.37, -2.49, -2.36,  ..., -2.31, -2.28, -2.22],
        [-2.37, -2.44, -2.44,  ..., -2.27, -2.26, -2.16],
        [-2.48, -2.33, -2.28,  ..., -2.30, -2.30, -2.27],
        ...,
        [-2.33, -2.52, -2.34,  ..., -2.31, -2.21, -2.16],
        [-2.38, -2.38, -2.33,  ..., -2.29, -2.26, -2.17],
        [-2.33, -2.55, -2.36,  ..., -2.29, -2.27, -2.16]], grad_fn=&lt;LogBackward0&gt;)</code></pre>
</div>
</div>
<p>Since the log of a division is the same as subtracting the logs of each value this can be further simplified</p>
<div class="cell" data-execution_count="7">
<div class="sourceCode cell-code" id="cb10"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb10-1"><a href="#cb10-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> log_softmax(x): <span class="cf">return</span> (x <span class="op">-</span> (x.exp().<span class="bu">sum</span>(axis<span class="op">=-</span><span class="dv">1</span>, keepdim<span class="op">=</span><span class="va">True</span>)).log())</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell" data-execution_count="8">
<div class="sourceCode cell-code" id="cb11"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb11-1"><a href="#cb11-1" aria-hidden="true" tabindex="-1"></a>log_softmax(preds)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="8">
<pre><code>tensor([[-2.37, -2.49, -2.36,  ..., -2.31, -2.28, -2.22],
        [-2.37, -2.44, -2.44,  ..., -2.27, -2.26, -2.16],
        [-2.48, -2.33, -2.28,  ..., -2.30, -2.30, -2.27],
        ...,
        [-2.33, -2.52, -2.34,  ..., -2.31, -2.21, -2.16],
        [-2.38, -2.38, -2.33,  ..., -2.29, -2.26, -2.17],
        [-2.33, -2.55, -2.36,  ..., -2.29, -2.27, -2.16]], grad_fn=&lt;SubBackward0&gt;)</code></pre>
</div>
</div>
<p>Then, there is a way to compute the log of the sum of exponentials in a more stable way, called the <a href="https://en.wikipedia.org/wiki/LogSumExp">LogSumExp trick</a>. The idea is to use the following formula:</p>
<p><span class="math display">\[\log \left ( \sum_{j=1}^{n} e^{x_{j}} \right ) = \log \left ( e^{a} \sum_{j=1}^{n} e^{x_{j}-a} \right ) = a + \log \left ( \sum_{j=1}^{n} e^{x_{j}-a} \right )\]</span></p>
<p>Where a is the maximum of the <span class="math inline">\(x_j\)</span> values, and is used to scale other values, preventing numerical overflow</p>
<div class="cell" data-execution_count="9">
<div class="sourceCode cell-code" id="cb13"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb13-1"><a href="#cb13-1" aria-hidden="true" tabindex="-1"></a>x <span class="op">=</span> preds.clone()</span>
<span id="cb13-2"><a href="#cb13-2" aria-hidden="true" tabindex="-1"></a>x.shape</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="9">
<pre><code>torch.Size([50000, 10])</code></pre>
</div>
</div>
<div class="cell" data-execution_count="10">
<div class="sourceCode cell-code" id="cb15"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb15-1"><a href="#cb15-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> logsumexp(x):</span>
<span id="cb15-2"><a href="#cb15-2" aria-hidden="true" tabindex="-1"></a>    <span class="co"># obtain the maximum x in each input row</span></span>
<span id="cb15-3"><a href="#cb15-3" aria-hidden="true" tabindex="-1"></a>    max_row_vals <span class="op">=</span> x.<span class="bu">max</span>(axis<span class="op">=-</span><span class="dv">1</span>)[<span class="dv">0</span>]</span>
<span id="cb15-4"><a href="#cb15-4" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> (max_row_vals <span class="op">+</span> (x <span class="op">-</span> max_row_vals[:, <span class="va">None</span>]).exp().<span class="bu">sum</span>(<span class="op">-</span><span class="dv">1</span>).log())</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell" data-execution_count="11">
<div class="sourceCode cell-code" id="cb16"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb16-1"><a href="#cb16-1" aria-hidden="true" tabindex="-1"></a>logsumexp(x)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="11">
<pre><code>tensor([2.28, 2.30, 2.29,  ..., 2.30, 2.28, 2.30], grad_fn=&lt;AddBackward0&gt;)</code></pre>
</div>
</div>
<p>Pytorch already has a pre build logsumexp and this can be used instead of the above. To check the same values are returned:</p>
<div class="cell" data-execution_count="12">
<div class="sourceCode cell-code" id="cb18"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb18-1"><a href="#cb18-1" aria-hidden="true" tabindex="-1"></a>test_close(logsumexp(x), x.logsumexp(dim<span class="op">=-</span><span class="dv">1</span>, keepdim<span class="op">=</span><span class="va">False</span>))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Hence it is possible to simplify the above log softmax to</p>
<div class="cell" data-execution_count="13">
<div class="sourceCode cell-code" id="cb19"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb19-1"><a href="#cb19-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> log_softmax(x):</span>
<span id="cb19-2"><a href="#cb19-2" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> x<span class="op">-</span>x.logsumexp(<span class="op">-</span><span class="dv">1</span>, keepdim<span class="op">=</span><span class="va">True</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell" data-execution_count="14">
<div class="sourceCode cell-code" id="cb20"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb20-1"><a href="#cb20-1" aria-hidden="true" tabindex="-1"></a>lsm_preds <span class="op">=</span> log_softmax(x)</span>
<span id="cb20-2"><a href="#cb20-2" aria-hidden="true" tabindex="-1"></a>lsm_preds</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="14">
<pre><code>tensor([[-2.37, -2.49, -2.36,  ..., -2.31, -2.28, -2.22],
        [-2.37, -2.44, -2.44,  ..., -2.27, -2.26, -2.16],
        [-2.48, -2.33, -2.28,  ..., -2.30, -2.30, -2.27],
        ...,
        [-2.33, -2.52, -2.34,  ..., -2.31, -2.21, -2.16],
        [-2.38, -2.38, -2.33,  ..., -2.29, -2.26, -2.17],
        [-2.33, -2.55, -2.36,  ..., -2.29, -2.27, -2.16]], grad_fn=&lt;SubBackward0&gt;)</code></pre>
</div>
</div>
<p>Having calculated the log softmax we now need a proper loss function. For classification we can use the cross entropy loss. This is defined as:</p>
<p><span class="math display">\[ CE Loss = \sum_i{x_i \log{ p(x_i)}}\]</span></p>
<p>where x is a vector of targets. Note that in Pytorch this is not one hot encoded and so the value can be used as an index to select the column of the preds that it refers to.</p>
<p>In this case the softmax can be interpreted as a probability (since it adds up to one for each case) and the output from the log_softmax is <span class="math inline">\(log(p(x_i))\)</span> is a vector for each class.</p>
<p>The CE loss can therefore be obtained by taking the mean of the CE loss over the dataset. Since x is zero over every element apart from the target, where it is one, this in practice means that all that has to be done is to calculate <span class="math inline">\(-\log{p(x_i)}\)</span> where i is the index of the actual target</p>
<p>Obtaining the index of the target can be done using the target as an index (as discussed above)</p>
<div class="cell" data-execution_count="15">
<div class="sourceCode cell-code" id="cb22"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb22-1"><a href="#cb22-1" aria-hidden="true" tabindex="-1"></a>y_train.shape, y_train[<span class="dv">0</span>:<span class="dv">3</span>]</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="15">
<pre><code>(torch.Size([50000]), tensor([5, 0, 4]))</code></pre>
</div>
</div>
<p>Since y_train is a vector we can use it to select the column as below. This could be summed and divided by the number of datapoint but the alternative is used, which is to take the mean</p>
<div class="cell" data-execution_count="16">
<div class="sourceCode cell-code" id="cb24"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb24-1"><a href="#cb24-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> nll(preds, targets):</span>
<span id="cb24-2"><a href="#cb24-2" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> <span class="op">-</span>preds[<span class="bu">range</span>(preds.shape[<span class="dv">0</span>]), targets].mean()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell" data-execution_count="17">
<div class="sourceCode cell-code" id="cb25"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb25-1"><a href="#cb25-1" aria-hidden="true" tabindex="-1"></a>loss <span class="op">=</span> nll(lsm_preds, y_train)</span>
<span id="cb25-2"><a href="#cb25-2" aria-hidden="true" tabindex="-1"></a>loss</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="17">
<pre><code>tensor(2.30, grad_fn=&lt;NegBackward0&gt;)</code></pre>
</div>
</div>
<p>Check that the loss value calculate above matches that from Pytorch</p>
<div class="cell" data-execution_count="18">
<div class="sourceCode cell-code" id="cb27"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb27-1"><a href="#cb27-1" aria-hidden="true" tabindex="-1"></a>test_close(F.nll_loss(F.log_softmax(x, dim<span class="op">=</span><span class="dv">1</span>), y_train), loss, <span class="fl">1.e-3</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell" data-execution_count="19">
<div class="sourceCode cell-code" id="cb28"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb28-1"><a href="#cb28-1" aria-hidden="true" tabindex="-1"></a>test_close(F.cross_entropy(x, y_train), loss, <span class="fl">1.e-3</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>We have now generate a loss function from first principles and can use Pytorch’s version moving forward</p>
</section>
<section id="development-of-a-training-loop" class="level1">
<h1>Development of a training loop</h1>
<p>The training loop repeats the following iteratively: * Load a batch of input data and the corresponding target outputs * Calculate the predictions from the input data * Calculate the loss based upon the targets and predictions * Calculate the gradients with respect to the loss of all of the model parameters * Update the parameters based upon the gradients so as to reduce the loss</p>
<section id="a-simple-training-loop" class="level2">
<h2 class="anchored" data-anchor-id="a-simple-training-loop">A simple training loop</h2>
<p>Before we train it is convenient to have a way to ascertain the accuracy of the model. To develop this a single batch of data will be processed</p>
<div class="cell" data-execution_count="20">
<div class="sourceCode cell-code" id="cb29"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb29-1"><a href="#cb29-1" aria-hidden="true" tabindex="-1"></a>bs <span class="op">=</span> <span class="dv">64</span></span>
<span id="cb29-2"><a href="#cb29-2" aria-hidden="true" tabindex="-1"></a><span class="co"># load a minibatch</span></span>
<span id="cb29-3"><a href="#cb29-3" aria-hidden="true" tabindex="-1"></a>xb <span class="op">=</span> x_train[<span class="dv">0</span>:bs]</span>
<span id="cb29-4"><a href="#cb29-4" aria-hidden="true" tabindex="-1"></a>yb <span class="op">=</span> y_train[<span class="dv">0</span>:bs]</span>
<span id="cb29-5"><a href="#cb29-5" aria-hidden="true" tabindex="-1"></a>preds <span class="op">=</span> model(xb)</span>
<span id="cb29-6"><a href="#cb29-6" aria-hidden="true" tabindex="-1"></a>preds.shape, preds[<span class="dv">0</span>]</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="20">
<pre><code>(torch.Size([64, 10]),
 tensor([-0.09, -0.21, -0.08,  0.10, -0.04,  0.08, -0.04, -0.03,  0.01,  0.06], grad_fn=&lt;SelectBackward0&gt;))</code></pre>
</div>
</div>
<div class="cell" data-execution_count="21">
<div class="sourceCode cell-code" id="cb31"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb31-1"><a href="#cb31-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Define a loss function and calculate the loss for the batch</span></span>
<span id="cb31-2"><a href="#cb31-2" aria-hidden="true" tabindex="-1"></a>loss_func <span class="op">=</span> F.cross_entropy</span>
<span id="cb31-3"><a href="#cb31-3" aria-hidden="true" tabindex="-1"></a>loss <span class="op">=</span> loss_func(preds, yb)</span>
<span id="cb31-4"><a href="#cb31-4" aria-hidden="true" tabindex="-1"></a>loss</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="21">
<pre><code>tensor(2.30, grad_fn=&lt;NllLossBackward0&gt;)</code></pre>
</div>
</div>
<section id="calculate-accuracy" class="level3">
<h3 class="anchored" data-anchor-id="calculate-accuracy">Calculate Accuracy</h3>
<p>The predicted class can be determined from the index of the class having the highest predicted value</p>
<div class="cell" data-execution_count="22">
<div class="sourceCode cell-code" id="cb33"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb33-1"><a href="#cb33-1" aria-hidden="true" tabindex="-1"></a>pred_class <span class="op">=</span> torch.argmax(preds, axis<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb33-2"><a href="#cb33-2" aria-hidden="true" tabindex="-1"></a>pred_class</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="22">
<pre><code>tensor([3, 9, 3, 8, 5, 9, 3, 9, 3, 9, 5, 3, 9, 9, 3, 9, 9, 5, 8, 7, 9, 5, 3, 8, 9, 5, 9, 5, 5, 9, 3, 5, 9, 7, 5, 7, 9, 9, 3, 9, 3, 5, 3, 8,
        3, 5, 9, 5, 9, 5, 3, 9, 3, 8, 9, 5, 9, 5, 9, 5, 8, 8, 9, 8])</code></pre>
</div>
</div>
<p>From this the accuracy can be calculated</p>
<div class="cell" data-execution_count="23">
<div class="sourceCode cell-code" id="cb35"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb35-1"><a href="#cb35-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> accuracy(preds, targets):</span>
<span id="cb35-2"><a href="#cb35-2" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> (torch.argmax(preds, axis<span class="op">=</span><span class="dv">1</span>) <span class="op">==</span> targets).<span class="bu">float</span>().mean()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell" data-execution_count="24">
<div class="sourceCode cell-code" id="cb36"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb36-1"><a href="#cb36-1" aria-hidden="true" tabindex="-1"></a>accuracy(preds, yb)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="24">
<pre><code>tensor(0.09)</code></pre>
</div>
</div>
<p>Not suprisingly, at this point the accuracy is what would be expected for a random prediction.</p>
<p>To improve this we need to train the model. To do that it is necessary to say what learning rate we would like and how many epochs to train for</p>
<div class="cell" data-execution_count="25">
<div class="sourceCode cell-code" id="cb38"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb38-1"><a href="#cb38-1" aria-hidden="true" tabindex="-1"></a>lr <span class="op">=</span> <span class="fl">0.5</span></span>
<span id="cb38-2"><a href="#cb38-2" aria-hidden="true" tabindex="-1"></a>epochs <span class="op">=</span> <span class="dv">3</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Now create a simple training loop following the above steps. Note that the loss, backward and parameter update is happening for every batch</p>
<div class="cell" data-execution_count="26">
<div class="sourceCode cell-code" id="cb39"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb39-1"><a href="#cb39-1" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> epoch <span class="kw">in</span> <span class="bu">range</span>(epochs):</span>
<span id="cb39-2"><a href="#cb39-2" aria-hidden="true" tabindex="-1"></a>    <span class="co"># iterate through batches</span></span>
<span id="cb39-3"><a href="#cb39-3" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> batch <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">0</span>, n, bs):</span>
<span id="cb39-4"><a href="#cb39-4" aria-hidden="true" tabindex="-1"></a>        <span class="co"># get data</span></span>
<span id="cb39-5"><a href="#cb39-5" aria-hidden="true" tabindex="-1"></a>        s <span class="op">=</span> <span class="bu">slice</span>(batch, <span class="bu">min</span>(n, batch<span class="op">+</span>bs))</span>
<span id="cb39-6"><a href="#cb39-6" aria-hidden="true" tabindex="-1"></a>        xs <span class="op">=</span> x_train[s]</span>
<span id="cb39-7"><a href="#cb39-7" aria-hidden="true" tabindex="-1"></a>        ys <span class="op">=</span> y_train[s]</span>
<span id="cb39-8"><a href="#cb39-8" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Pass data through the model</span></span>
<span id="cb39-9"><a href="#cb39-9" aria-hidden="true" tabindex="-1"></a>        preds <span class="op">=</span> model(xs)</span>
<span id="cb39-10"><a href="#cb39-10" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Calculate loss</span></span>
<span id="cb39-11"><a href="#cb39-11" aria-hidden="true" tabindex="-1"></a>        loss <span class="op">=</span> loss_func(preds, ys)</span>
<span id="cb39-12"><a href="#cb39-12" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Calculate the gradients</span></span>
<span id="cb39-13"><a href="#cb39-13" aria-hidden="true" tabindex="-1"></a>        loss.backward()</span>
<span id="cb39-14"><a href="#cb39-14" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Print the loss periodically</span></span>
<span id="cb39-15"><a href="#cb39-15" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> batch <span class="op">//</span> bs <span class="op">//</span> <span class="dv">10</span> <span class="op">==</span> <span class="dv">0</span>: <span class="bu">print</span>(<span class="ss">f"Loss: </span><span class="sc">{</span>loss<span class="sc">.</span>item()<span class="sc">}</span><span class="ss">, accuracy = </span><span class="sc">{</span>accuracy(preds, ys)<span class="sc">.</span>item()<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb39-16"><a href="#cb39-16" aria-hidden="true" tabindex="-1"></a>        <span class="cf">with</span> torch.no_grad():</span>
<span id="cb39-17"><a href="#cb39-17" aria-hidden="true" tabindex="-1"></a>            <span class="cf">for</span> l <span class="kw">in</span> model.layers:</span>
<span id="cb39-18"><a href="#cb39-18" aria-hidden="true" tabindex="-1"></a>                <span class="cf">if</span> <span class="bu">hasattr</span>(l, <span class="st">"weight"</span>):</span>
<span id="cb39-19"><a href="#cb39-19" aria-hidden="true" tabindex="-1"></a>                    l.weight <span class="op">-=</span> l.weight.grad <span class="op">*</span> lr</span>
<span id="cb39-20"><a href="#cb39-20" aria-hidden="true" tabindex="-1"></a>                    l.bias <span class="op">-=</span> l.bias.grad <span class="op">*</span> lr</span>
<span id="cb39-21"><a href="#cb39-21" aria-hidden="true" tabindex="-1"></a>                    l.weight.grad.zero_()</span>
<span id="cb39-22"><a href="#cb39-22" aria-hidden="true" tabindex="-1"></a>                    l.bias.grad.zero_()</span>
<span id="cb39-23"><a href="#cb39-23" aria-hidden="true" tabindex="-1"></a>        </span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Loss: 2.3036487102508545, accuracy = 0.09375
Loss: 2.2052316665649414, accuracy = 0.296875
Loss: 2.1905035972595215, accuracy = 0.21875
Loss: 2.010064125061035, accuracy = 0.53125
Loss: 1.9125093221664429, accuracy = 0.5
Loss: 1.7081104516983032, accuracy = 0.703125
Loss: 1.6426200866699219, accuracy = 0.5
Loss: 1.6326062679290771, accuracy = 0.625
Loss: 1.5491729974746704, accuracy = 0.4375
Loss: 1.5245637893676758, accuracy = 0.53125
Loss: 0.12374816089868546, accuracy = 0.96875
Loss: 0.14763614535331726, accuracy = 0.984375
Loss: 0.29614493250846863, accuracy = 0.890625
Loss: 0.16717804968357086, accuracy = 0.9375
Loss: 0.1868995726108551, accuracy = 0.90625
Loss: 0.05588085949420929, accuracy = 0.984375
Loss: 0.10521863400936127, accuracy = 0.96875
Loss: 0.2990257740020752, accuracy = 0.9375
Loss: 0.04911200702190399, accuracy = 1.0
Loss: 0.25950485467910767, accuracy = 0.9375
Loss: 0.09232573211193085, accuracy = 0.96875
Loss: 0.10159078985452652, accuracy = 0.984375
Loss: 0.28459155559539795, accuracy = 0.9375
Loss: 0.05941237136721611, accuracy = 0.984375
Loss: 0.11075811833143234, accuracy = 0.9375
Loss: 0.031431593000888824, accuracy = 0.984375
Loss: 0.07170089334249496, accuracy = 0.984375
Loss: 0.24644441902637482, accuracy = 0.953125
Loss: 0.05402196943759918, accuracy = 0.984375
Loss: 0.18466435372829437, accuracy = 0.984375</code></pre>
</div>
</div>
</section>
</section>
<section id="adding-parameters-and-optim" class="level2">
<h2 class="anchored" data-anchor-id="adding-parameters-and-optim">Adding parameters and optim</h2>
<p>The above training loop works but accessing the model parameters us cumbersome since it requires advanced knowledge of the layers. Pytorch has some methods to allow accessing and modifying layer information in a more straightforward manner</p>
<section id="parameters" class="level3">
<h3 class="anchored" data-anchor-id="parameters">Parameters</h3>
<p>Recreate the model with individual layers</p>
<div class="cell" data-execution_count="27">
<div class="sourceCode cell-code" id="cb41"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb41-1"><a href="#cb41-1" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> Model(nn.Module):</span>
<span id="cb41-2"><a href="#cb41-2" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>, n_in, nh, n_out):</span>
<span id="cb41-3"><a href="#cb41-3" aria-hidden="true" tabindex="-1"></a>        <span class="bu">super</span>().<span class="fu">__init__</span>()</span>
<span id="cb41-4"><a href="#cb41-4" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.l1 <span class="op">=</span> nn.Linear(n_in,nh)</span>
<span id="cb41-5"><a href="#cb41-5" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.relu <span class="op">=</span> nn.ReLU()</span>
<span id="cb41-6"><a href="#cb41-6" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.l2 <span class="op">=</span> nn.Linear(nh,n_out)</span>
<span id="cb41-7"><a href="#cb41-7" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb41-8"><a href="#cb41-8" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__call__</span>(<span class="va">self</span>, x):</span>
<span id="cb41-9"><a href="#cb41-9" aria-hidden="true" tabindex="-1"></a>        x <span class="op">=</span> <span class="va">self</span>.l2(<span class="va">self</span>.relu(<span class="va">self</span>.l1(x)))</span>
<span id="cb41-10"><a href="#cb41-10" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> x</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell" data-execution_count="28">
<div class="sourceCode cell-code" id="cb42"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb42-1"><a href="#cb42-1" aria-hidden="true" tabindex="-1"></a>model <span class="op">=</span> Model(m, nh, c)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Examine the model parameters</p>
<div class="cell" data-execution_count="29">
<div class="sourceCode cell-code" id="cb43"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb43-1"><a href="#cb43-1" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> name, layer <span class="kw">in</span> model.named_children():</span>
<span id="cb43-2"><a href="#cb43-2" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"Layer: </span><span class="sc">{</span>name<span class="sc">}</span><span class="ss">, Parameters: </span><span class="sc">{</span>layer<span class="sc">}</span><span class="ss">"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Layer: l1, Parameters: Linear(in_features=784, out_features=50, bias=True)
Layer: relu, Parameters: ReLU()
Layer: l2, Parameters: Linear(in_features=50, out_features=10, bias=True)</code></pre>
</div>
</div>
<p>The layers can be accessed using the name alone, for example</p>
<div class="cell" data-execution_count="30">
<div class="sourceCode cell-code" id="cb45"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb45-1"><a href="#cb45-1" aria-hidden="true" tabindex="-1"></a>model.l1</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="30">
<pre><code>Linear(in_features=784, out_features=50, bias=True)</code></pre>
</div>
</div>
<p>The layer parameters can also be accessed by the model.parameters property, however, this is an iterator and hence needs to be listed through a loop or creation of a list…</p>
<div class="cell" data-execution_count="31">
<div class="sourceCode cell-code" id="cb47"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb47-1"><a href="#cb47-1" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> param <span class="kw">in</span> model.parameters():</span>
<span id="cb47-2"><a href="#cb47-2" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(param.shape)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>torch.Size([50, 784])
torch.Size([50])
torch.Size([10, 50])
torch.Size([10])</code></pre>
</div>
</div>
<div class="cell" data-execution_count="32">
<div class="sourceCode cell-code" id="cb49"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb49-1"><a href="#cb49-1" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> param <span class="kw">in</span> model.parameters():</span>
<span id="cb49-2"><a href="#cb49-2" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(param[<span class="dv">0</span>:<span class="dv">2</span>])</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>tensor([[ 0.04,  0.03, -0.02,  ...,  0.03,  0.03,  0.00],
        [ 0.04,  0.01,  0.03,  ..., -0.01,  0.02,  0.03]], grad_fn=&lt;SliceBackward0&gt;)
tensor([-0.01, -0.01], grad_fn=&lt;SliceBackward0&gt;)
tensor([[-0.05,  0.02,  0.07,  0.09,  0.10,  0.12, -0.13,  0.10, -0.09, -0.08, -0.12, -0.01,  0.07, -0.00,  0.12, -0.03, -0.07, -0.14,
          0.10,  0.13, -0.12,  0.14,  0.12,  0.08, -0.11,  0.03, -0.09,  0.12,  0.01, -0.03,  0.06, -0.00,  0.01, -0.05,  0.11,  0.14,
          0.07,  0.05, -0.09, -0.03, -0.01, -0.01,  0.08,  0.02, -0.09, -0.05,  0.03,  0.13, -0.08,  0.13],
        [ 0.09, -0.04,  0.00,  0.14, -0.13, -0.06,  0.03, -0.09, -0.11,  0.05,  0.04, -0.02, -0.04, -0.03,  0.01, -0.10, -0.03, -0.02,
          0.00,  0.07,  0.10, -0.08, -0.14, -0.02, -0.13, -0.08,  0.07,  0.04, -0.13, -0.13, -0.05,  0.12, -0.08,  0.13,  0.13, -0.10,
          0.06,  0.08, -0.13, -0.08, -0.06, -0.11,  0.07,  0.06,  0.09,  0.04, -0.13,  0.04, -0.10, -0.01]], grad_fn=&lt;SliceBackward0&gt;)
tensor([-0.01, -0.06], grad_fn=&lt;SliceBackward0&gt;)</code></pre>
</div>
</div>
<p>Using parameters it is possible to simplify the code to optimise the weights and biases by looping through teh model parameters. It is also possible to zero all of the model’s gradients with a since call:</p>
<div class="cell" data-execution_count="33">
<div class="sourceCode cell-code" id="cb51"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb51-1"><a href="#cb51-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> fit():</span>
<span id="cb51-2"><a href="#cb51-2" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> epoch <span class="kw">in</span> <span class="bu">range</span>(epochs):</span>
<span id="cb51-3"><a href="#cb51-3" aria-hidden="true" tabindex="-1"></a>        <span class="co"># iterate through batches</span></span>
<span id="cb51-4"><a href="#cb51-4" aria-hidden="true" tabindex="-1"></a>        <span class="cf">for</span> batch <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">0</span>, n, bs):</span>
<span id="cb51-5"><a href="#cb51-5" aria-hidden="true" tabindex="-1"></a>            <span class="co"># get data</span></span>
<span id="cb51-6"><a href="#cb51-6" aria-hidden="true" tabindex="-1"></a>            s <span class="op">=</span> <span class="bu">slice</span>(batch, <span class="bu">min</span>(n, batch<span class="op">+</span>bs))</span>
<span id="cb51-7"><a href="#cb51-7" aria-hidden="true" tabindex="-1"></a>            xs <span class="op">=</span> x_train[s]</span>
<span id="cb51-8"><a href="#cb51-8" aria-hidden="true" tabindex="-1"></a>            ys <span class="op">=</span> y_train[s]</span>
<span id="cb51-9"><a href="#cb51-9" aria-hidden="true" tabindex="-1"></a>            <span class="co"># Pass data through the model</span></span>
<span id="cb51-10"><a href="#cb51-10" aria-hidden="true" tabindex="-1"></a>            preds <span class="op">=</span> model(xs)</span>
<span id="cb51-11"><a href="#cb51-11" aria-hidden="true" tabindex="-1"></a>            <span class="co"># Calculate loss</span></span>
<span id="cb51-12"><a href="#cb51-12" aria-hidden="true" tabindex="-1"></a>            loss <span class="op">=</span> loss_func(preds, ys)</span>
<span id="cb51-13"><a href="#cb51-13" aria-hidden="true" tabindex="-1"></a>            <span class="co"># Calculate the gradients</span></span>
<span id="cb51-14"><a href="#cb51-14" aria-hidden="true" tabindex="-1"></a>            loss.backward()</span>
<span id="cb51-15"><a href="#cb51-15" aria-hidden="true" tabindex="-1"></a>            <span class="co"># Print the loss periodically</span></span>
<span id="cb51-16"><a href="#cb51-16" aria-hidden="true" tabindex="-1"></a>            <span class="cf">if</span> batch <span class="op">//</span> bs <span class="op">//</span> <span class="dv">10</span> <span class="op">==</span> <span class="dv">0</span>: <span class="bu">print</span>(<span class="ss">f"Loss: </span><span class="sc">{</span>loss<span class="sc">.</span>item()<span class="sc">}</span><span class="ss">, accuracy = </span><span class="sc">{</span>accuracy(preds, ys)<span class="sc">.</span>item()<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb51-17"><a href="#cb51-17" aria-hidden="true" tabindex="-1"></a>            <span class="cf">with</span> torch.no_grad():</span>
<span id="cb51-18"><a href="#cb51-18" aria-hidden="true" tabindex="-1"></a>                <span class="cf">for</span> params <span class="kw">in</span> model.parameters():</span>
<span id="cb51-19"><a href="#cb51-19" aria-hidden="true" tabindex="-1"></a>                    params <span class="op">-=</span> params.grad <span class="op">*</span> lr</span>
<span id="cb51-20"><a href="#cb51-20" aria-hidden="true" tabindex="-1"></a>                model.zero_grad()                      </span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell" data-execution_count="34">
<div class="sourceCode cell-code" id="cb52"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb52-1"><a href="#cb52-1" aria-hidden="true" tabindex="-1"></a>fit()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Loss: 2.309434175491333, accuracy = 0.0625
Loss: 2.177271842956543, accuracy = 0.234375
Loss: 2.259394645690918, accuracy = 0.078125
Loss: 2.0509822368621826, accuracy = 0.578125
Loss: 1.9572300910949707, accuracy = 0.34375
Loss: 1.7929021120071411, accuracy = 0.71875
Loss: 1.6334275007247925, accuracy = 0.65625
Loss: 1.5452338457107544, accuracy = 0.625
Loss: 1.507757306098938, accuracy = 0.4375
Loss: 1.6010795831680298, accuracy = 0.484375
Loss: 0.2006874829530716, accuracy = 0.953125
Loss: 0.11892185360193253, accuracy = 0.96875
Loss: 0.2844753861427307, accuracy = 0.90625
Loss: 0.17238563299179077, accuracy = 0.96875
Loss: 0.15464989840984344, accuracy = 0.90625
Loss: 0.04285932332277298, accuracy = 1.0
Loss: 0.12839168310165405, accuracy = 0.96875
Loss: 0.3218374252319336, accuracy = 0.953125
Loss: 0.09430787712335587, accuracy = 0.96875
Loss: 0.3029904365539551, accuracy = 0.953125
Loss: 0.18196934461593628, accuracy = 0.9375
Loss: 0.0731976106762886, accuracy = 0.984375
Loss: 0.29567304253578186, accuracy = 0.9375
Loss: 0.0792182981967926, accuracy = 0.984375
Loss: 0.09979861974716187, accuracy = 0.953125
Loss: 0.028896179050207138, accuracy = 1.0
Loss: 0.10094335675239563, accuracy = 0.96875
Loss: 0.28324049711227417, accuracy = 0.9375
Loss: 0.055503442883491516, accuracy = 0.984375
Loss: 0.2787169814109802, accuracy = 0.96875</code></pre>
</div>
</div>
<p>The way that the model parameters are setup is by Pytorch overriding the <strong>setattrib</strong> method in nn.Module. The way that this works is as below</p>
<div class="cell" data-execution_count="35">
<div class="sourceCode cell-code" id="cb54"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb54-1"><a href="#cb54-1" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> DummyModule():</span>
<span id="cb54-2"><a href="#cb54-2" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>, n_in, nh, n_out):</span>
<span id="cb54-3"><a href="#cb54-3" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>._modules <span class="op">=</span> {}</span>
<span id="cb54-4"><a href="#cb54-4" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.l1 <span class="op">=</span> nn.Linear(n_in,nh)</span>
<span id="cb54-5"><a href="#cb54-5" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.relu <span class="op">=</span> nn.ReLU()</span>
<span id="cb54-6"><a href="#cb54-6" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.l2 <span class="op">=</span> nn.Linear(nh,n_out)</span>
<span id="cb54-7"><a href="#cb54-7" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb54-8"><a href="#cb54-8" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__setattr__</span>(<span class="va">self</span>, k,v):</span>
<span id="cb54-9"><a href="#cb54-9" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Assign the layers to the modules dict before calling the set attribute class.  The parameters are </span></span>
<span id="cb54-10"><a href="#cb54-10" aria-hidden="true" tabindex="-1"></a>        <span class="co"># simply name (k), value (v)</span></span>
<span id="cb54-11"><a href="#cb54-11" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> <span class="kw">not</span> k.startswith(<span class="st">"_"</span>):</span>
<span id="cb54-12"><a href="#cb54-12" aria-hidden="true" tabindex="-1"></a>            <span class="va">self</span>._modules[k] <span class="op">=</span> v</span>
<span id="cb54-13"><a href="#cb54-13" aria-hidden="true" tabindex="-1"></a>        <span class="bu">super</span>().<span class="fu">__setattr__</span>(k,v)</span>
<span id="cb54-14"><a href="#cb54-14" aria-hidden="true" tabindex="-1"></a>            </span>
<span id="cb54-15"><a href="#cb54-15" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__repr__</span>(<span class="va">self</span>): </span>
<span id="cb54-16"><a href="#cb54-16" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Setup so that the official string representation of the class instance is a listing of the module</span></span>
<span id="cb54-17"><a href="#cb54-17" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> <span class="ss">f"</span><span class="sc">{</span><span class="va">self</span><span class="sc">.</span>_modules<span class="sc">}</span><span class="ss">"</span></span>
<span id="cb54-18"><a href="#cb54-18" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb54-19"><a href="#cb54-19" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> parameters(<span class="va">self</span>):</span>
<span id="cb54-20"><a href="#cb54-20" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Create an iterator to yield all of the model parameters</span></span>
<span id="cb54-21"><a href="#cb54-21" aria-hidden="true" tabindex="-1"></a>        <span class="cf">for</span> layer <span class="kw">in</span> <span class="va">self</span>._modules.values():</span>
<span id="cb54-22"><a href="#cb54-22" aria-hidden="true" tabindex="-1"></a>            <span class="cf">for</span> param <span class="kw">in</span> layer.parameters(): <span class="cf">yield</span>(param)</span>
<span id="cb54-23"><a href="#cb54-23" aria-hidden="true" tabindex="-1"></a>            </span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell" data-execution_count="36">
<div class="sourceCode cell-code" id="cb55"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb55-1"><a href="#cb55-1" aria-hidden="true" tabindex="-1"></a>dm <span class="op">=</span> DummyModule(m, nh, c)</span>
<span id="cb55-2"><a href="#cb55-2" aria-hidden="true" tabindex="-1"></a>dm</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="36">
<pre><code>{'l1': Linear(in_features=784, out_features=50, bias=True), 'relu': ReLU(), 'l2': Linear(in_features=50, out_features=10, bias=True)}</code></pre>
</div>
</div>
<div class="cell" data-execution_count="37">
<div class="sourceCode cell-code" id="cb57"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb57-1"><a href="#cb57-1" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> param <span class="kw">in</span> dm.parameters():</span>
<span id="cb57-2"><a href="#cb57-2" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(param.shape)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>torch.Size([50, 784])
torch.Size([50])
torch.Size([10, 50])
torch.Size([10])</code></pre>
</div>
</div>
<p>This approach won’t work as it with lists of layers as things were originally setup. To allow this. to work the layers have to be individually registered</p>
<div class="cell" data-execution_count="38">
<div class="sourceCode cell-code" id="cb59"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb59-1"><a href="#cb59-1" aria-hidden="true" tabindex="-1"></a>layers <span class="op">=</span> [nn.Linear(m,nh), nn.ReLU(), nn.Linear(nh,<span class="dv">10</span>)]</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell" data-execution_count="39">
<div class="sourceCode cell-code" id="cb60"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb60-1"><a href="#cb60-1" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> Model(nn.Module):</span>
<span id="cb60-2"><a href="#cb60-2" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>, layers):</span>
<span id="cb60-3"><a href="#cb60-3" aria-hidden="true" tabindex="-1"></a>        <span class="bu">super</span>().<span class="fu">__init__</span>()</span>
<span id="cb60-4"><a href="#cb60-4" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.layers <span class="op">=</span> layers</span>
<span id="cb60-5"><a href="#cb60-5" aria-hidden="true" tabindex="-1"></a>        <span class="cf">for</span> i, layer <span class="kw">in</span> <span class="bu">enumerate</span>(<span class="va">self</span>.layers):</span>
<span id="cb60-6"><a href="#cb60-6" aria-hidden="true" tabindex="-1"></a>            <span class="va">self</span>.add_module(<span class="ss">f"layer_</span><span class="sc">{</span>i<span class="sc">}</span><span class="ss">"</span>, layer)</span>
<span id="cb60-7"><a href="#cb60-7" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb60-8"><a href="#cb60-8" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__call__</span>(<span class="va">self</span>, x):</span>
<span id="cb60-9"><a href="#cb60-9" aria-hidden="true" tabindex="-1"></a>        <span class="cf">for</span> layer <span class="kw">in</span> <span class="va">self</span>.layers:</span>
<span id="cb60-10"><a href="#cb60-10" aria-hidden="true" tabindex="-1"></a>            x <span class="op">=</span> layer(x)</span>
<span id="cb60-11"><a href="#cb60-11" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> x</span>
<span id="cb60-12"><a href="#cb60-12" aria-hidden="true" tabindex="-1"></a>    </span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell" data-execution_count="40">
<div class="sourceCode cell-code" id="cb61"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb61-1"><a href="#cb61-1" aria-hidden="true" tabindex="-1"></a>model <span class="op">=</span> Model(layers)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell" data-execution_count="41">
<div class="sourceCode cell-code" id="cb62"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb62-1"><a href="#cb62-1" aria-hidden="true" tabindex="-1"></a>model</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="41">
<pre><code>Model(
  (layer_0): Linear(in_features=784, out_features=50, bias=True)
  (layer_1): ReLU()
  (layer_2): Linear(in_features=50, out_features=10, bias=True)
)</code></pre>
</div>
</div>
<div class="cell" data-execution_count="42">
<div class="sourceCode cell-code" id="cb64"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb64-1"><a href="#cb64-1" aria-hidden="true" tabindex="-1"></a>fit()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Loss: 2.3222596645355225, accuracy = 0.03125
Loss: 2.2330336570739746, accuracy = 0.21875
Loss: 2.222136974334717, accuracy = 0.140625
Loss: 2.079106330871582, accuracy = 0.421875
Loss: 1.958361029624939, accuracy = 0.5625
Loss: 1.7925820350646973, accuracy = 0.625
Loss: 1.675372838973999, accuracy = 0.515625
Loss: 1.6172857284545898, accuracy = 0.609375
Loss: 1.4986895322799683, accuracy = 0.546875
Loss: 1.5764800310134888, accuracy = 0.515625
Loss: 0.16430063545703888, accuracy = 0.953125
Loss: 0.12203794717788696, accuracy = 0.984375
Loss: 0.3307473063468933, accuracy = 0.890625
Loss: 0.21634256839752197, accuracy = 0.921875
Loss: 0.17808055877685547, accuracy = 0.921875
Loss: 0.04548545181751251, accuracy = 0.984375
Loss: 0.13622808456420898, accuracy = 0.96875
Loss: 0.32709184288978577, accuracy = 0.9375
Loss: 0.09109017997980118, accuracy = 0.984375
Loss: 0.27433082461357117, accuracy = 0.953125
Loss: 0.09979915618896484, accuracy = 0.96875
Loss: 0.08315068483352661, accuracy = 0.984375
Loss: 0.27988025546073914, accuracy = 0.90625
Loss: 0.1201467365026474, accuracy = 0.953125
Loss: 0.14109008014202118, accuracy = 0.9375
Loss: 0.01877472549676895, accuracy = 1.0
Loss: 0.10770482569932938, accuracy = 0.96875
Loss: 0.3286954462528229, accuracy = 0.953125
Loss: 0.06740975379943848, accuracy = 0.984375
Loss: 0.18299852311611176, accuracy = 0.984375</code></pre>
</div>
</div>
<p>Registering the layers can be done using the nn.ModuleList class: <a href="https://pytorch.org/docs/stable/generated/torch.nn.ModuleList.html?highlight=nn+modulelist#torch.nn.ModuleList">Link to nn.ModuleList docs</a></p>
<p>Thus this allows further simplification</p>
<div class="cell" data-execution_count="43">
<div class="sourceCode cell-code" id="cb66"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb66-1"><a href="#cb66-1" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> SequentialModel(nn.Module):</span>
<span id="cb66-2"><a href="#cb66-2" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>, layers):</span>
<span id="cb66-3"><a href="#cb66-3" aria-hidden="true" tabindex="-1"></a>        <span class="bu">super</span>().<span class="fu">__init__</span>()</span>
<span id="cb66-4"><a href="#cb66-4" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.layers <span class="op">=</span> nn.ModuleList(layers)</span>
<span id="cb66-5"><a href="#cb66-5" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb66-6"><a href="#cb66-6" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__call__</span>(<span class="va">self</span>, x):</span>
<span id="cb66-7"><a href="#cb66-7" aria-hidden="true" tabindex="-1"></a>        <span class="cf">for</span> l <span class="kw">in</span> <span class="va">self</span>.layers: x <span class="op">=</span> l(x)</span>
<span id="cb66-8"><a href="#cb66-8" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> x</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell" data-execution_count="44">
<div class="sourceCode cell-code" id="cb67"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb67-1"><a href="#cb67-1" aria-hidden="true" tabindex="-1"></a>model <span class="op">=</span> SequentialModel(layers)</span>
<span id="cb67-2"><a href="#cb67-2" aria-hidden="true" tabindex="-1"></a>model</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="44">
<pre><code>SequentialModel(
  (layers): ModuleList(
    (0): Linear(in_features=784, out_features=50, bias=True)
    (1): ReLU()
    (2): Linear(in_features=50, out_features=10, bias=True)
  )
)</code></pre>
</div>
</div>
<div class="cell" data-execution_count="45">
<div class="sourceCode cell-code" id="cb69"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb69-1"><a href="#cb69-1" aria-hidden="true" tabindex="-1"></a>fit()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Loss: 0.06515892595052719, accuracy = 0.96875
Loss: 0.06317746639251709, accuracy = 0.984375
Loss: 0.21157535910606384, accuracy = 0.921875
Loss: 0.10860879719257355, accuracy = 0.96875
Loss: 0.08964528143405914, accuracy = 0.9375
Loss: 0.011501152999699116, accuracy = 1.0
Loss: 0.08443643152713776, accuracy = 0.96875
Loss: 0.3277687132358551, accuracy = 0.9375
Loss: 0.06517940014600754, accuracy = 0.984375
Loss: 0.17099246382713318, accuracy = 0.96875
Loss: 0.04173600673675537, accuracy = 0.984375
Loss: 0.04945621266961098, accuracy = 0.984375
Loss: 0.1965624988079071, accuracy = 0.90625
Loss: 0.0814109668135643, accuracy = 0.96875
Loss: 0.06253797560930252, accuracy = 0.96875
Loss: 0.009009594097733498, accuracy = 1.0
Loss: 0.08011716604232788, accuracy = 0.96875
Loss: 0.32447099685668945, accuracy = 0.9375
Loss: 0.05112294852733612, accuracy = 0.984375
Loss: 0.15682904422283173, accuracy = 0.984375
Loss: 0.02698095701634884, accuracy = 1.0
Loss: 0.035535961389541626, accuracy = 0.984375
Loss: 0.15110039710998535, accuracy = 0.921875
Loss: 0.0608980655670166, accuracy = 0.96875
Loss: 0.03945880010724068, accuracy = 1.0
Loss: 0.005177198443561792, accuracy = 1.0
Loss: 0.07748386263847351, accuracy = 0.96875
Loss: 0.3055875599384308, accuracy = 0.9375
Loss: 0.04133985936641693, accuracy = 0.984375
Loss: 0.16388559341430664, accuracy = 0.984375</code></pre>
</div>
</div>
<div class="cell" data-execution_count="46">
<div class="sourceCode cell-code" id="cb71"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb71-1"><a href="#cb71-1" aria-hidden="true" tabindex="-1"></a>loss_func(model(xb), yb), accuracy(model(xb), yb)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="46">
<pre><code>(tensor(0.02, grad_fn=&lt;NllLossBackward0&gt;), tensor(1.))</code></pre>
</div>
</div>
</section>
<section id="the-nn.sequential-class" class="level3">
<h3 class="anchored" data-anchor-id="the-nn.sequential-class">The nn.Sequential Class</h3>
<p>This class does what is done above, in other words it takes a list of layers and created a model by registering and then saving the layers in sequence.</p>
<p>The sequential class will not accept a list as an input and so we have to pass in the individual layers</p>
<div class="cell" data-execution_count="47">
<div class="sourceCode cell-code" id="cb73"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb73-1"><a href="#cb73-1" aria-hidden="true" tabindex="-1"></a>model <span class="op">=</span> nn.Sequential(nn.Linear(m, nh), nn.ReLU(), nn.Linear(nh, c))</span>
<span id="cb73-2"><a href="#cb73-2" aria-hidden="true" tabindex="-1"></a>model</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="47">
<pre><code>Sequential(
  (0): Linear(in_features=784, out_features=50, bias=True)
  (1): ReLU()
  (2): Linear(in_features=50, out_features=10, bias=True)
)</code></pre>
</div>
</div>
<div class="cell" data-execution_count="48">
<div class="sourceCode cell-code" id="cb75"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb75-1"><a href="#cb75-1" aria-hidden="true" tabindex="-1"></a>fit()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Loss: 2.3087124824523926, accuracy = 0.09375
Loss: 2.220724582672119, accuracy = 0.4375
Loss: 2.2094054222106934, accuracy = 0.15625
Loss: 2.0799782276153564, accuracy = 0.484375
Loss: 1.9859000444412231, accuracy = 0.421875
Loss: 1.8239319324493408, accuracy = 0.5625
Loss: 1.692657232284546, accuracy = 0.625
Loss: 1.5962902307510376, accuracy = 0.671875
Loss: 1.4929006099700928, accuracy = 0.46875
Loss: 1.5572547912597656, accuracy = 0.53125
Loss: 0.2031664103269577, accuracy = 0.90625
Loss: 0.12023147940635681, accuracy = 0.984375
Loss: 0.36551305651664734, accuracy = 0.890625
Loss: 0.1421089768409729, accuracy = 0.96875
Loss: 0.13040338456630707, accuracy = 0.921875
Loss: 0.03445771709084511, accuracy = 0.984375
Loss: 0.14158782362937927, accuracy = 0.96875
Loss: 0.29142311215400696, accuracy = 0.953125
Loss: 0.1052810475230217, accuracy = 0.953125
Loss: 0.22577130794525146, accuracy = 0.984375
Loss: 0.20330604910850525, accuracy = 0.921875
Loss: 0.1524616777896881, accuracy = 0.96875
Loss: 0.3139619827270508, accuracy = 0.921875
Loss: 0.10483880341053009, accuracy = 0.953125
Loss: 0.09913913160562515, accuracy = 0.9375
Loss: 0.02614644728600979, accuracy = 1.0
Loss: 0.1354278326034546, accuracy = 0.96875
Loss: 0.2590445876121521, accuracy = 0.953125
Loss: 0.06993013620376587, accuracy = 0.96875
Loss: 0.1877637505531311, accuracy = 0.984375</code></pre>
</div>
</div>
</section>
<section id="introducing-the-optimiser-class-optim" class="level3">
<h3 class="anchored" data-anchor-id="introducing-the-optimiser-class-optim">Introducing the optimiser class Optim</h3>
<p>So far we have developed the loss function and the model but the appliction of the weights has been done using a relatively simple implmentation of SGD. The process of optimising the model parameters can be built into a class. In Pytorch this is the Optim class. This will now be developed.</p>
<p>Note that in the class below there are two things to ensure: 1. The params are converted into a list in the init function (to facilitate iteration) 2. when zeroing the gradients it is important to use the in place version of the function</p>
<div class="cell" data-execution_count="49">
<div class="sourceCode cell-code" id="cb77"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb77-1"><a href="#cb77-1" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> Optimizer():</span>
<span id="cb77-2"><a href="#cb77-2" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>, params, lr<span class="op">=</span><span class="fl">0.5</span>):</span>
<span id="cb77-3"><a href="#cb77-3" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.params <span class="op">=</span> <span class="bu">list</span>(params)<span class="op">;</span> <span class="va">self</span>.lr <span class="op">=</span> lr</span>
<span id="cb77-4"><a href="#cb77-4" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb77-5"><a href="#cb77-5" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> step(<span class="va">self</span>):</span>
<span id="cb77-6"><a href="#cb77-6" aria-hidden="true" tabindex="-1"></a>        <span class="cf">with</span> torch.no_grad():</span>
<span id="cb77-7"><a href="#cb77-7" aria-hidden="true" tabindex="-1"></a>            <span class="cf">for</span> param <span class="kw">in</span> <span class="va">self</span>.params: param <span class="op">-=</span> param.grad <span class="op">*</span> <span class="va">self</span>.lr</span>
<span id="cb77-8"><a href="#cb77-8" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb77-9"><a href="#cb77-9" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> zero_grad(<span class="va">self</span>):</span>
<span id="cb77-10"><a href="#cb77-10" aria-hidden="true" tabindex="-1"></a>        <span class="cf">for</span> param <span class="kw">in</span> <span class="va">self</span>.params: param.grad.data.zero_() </span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell" data-execution_count="50">
<div class="sourceCode cell-code" id="cb78"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb78-1"><a href="#cb78-1" aria-hidden="true" tabindex="-1"></a>model <span class="op">=</span> nn.Sequential(nn.Linear(m, nh), nn.ReLU(), nn.Linear(nh, c))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell" data-execution_count="51">
<div class="sourceCode cell-code" id="cb79"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb79-1"><a href="#cb79-1" aria-hidden="true" tabindex="-1"></a>opt <span class="op">=</span> Optimizer(model.parameters())</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Update the training loop to work with the optimizer</p>
<div class="cell" data-execution_count="52">
<div class="sourceCode cell-code" id="cb80"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb80-1"><a href="#cb80-1" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> epoch <span class="kw">in</span> <span class="bu">range</span>(epochs):</span>
<span id="cb80-2"><a href="#cb80-2" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> batch <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">0</span>, n, bs):</span>
<span id="cb80-3"><a href="#cb80-3" aria-hidden="true" tabindex="-1"></a>        <span class="co"># get data</span></span>
<span id="cb80-4"><a href="#cb80-4" aria-hidden="true" tabindex="-1"></a>        s <span class="op">=</span> <span class="bu">slice</span>(batch, <span class="bu">min</span>(n, batch<span class="op">+</span>bs))</span>
<span id="cb80-5"><a href="#cb80-5" aria-hidden="true" tabindex="-1"></a>        xs <span class="op">=</span> x_train[s]</span>
<span id="cb80-6"><a href="#cb80-6" aria-hidden="true" tabindex="-1"></a>        ys <span class="op">=</span> y_train[s]</span>
<span id="cb80-7"><a href="#cb80-7" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Pass data through the model</span></span>
<span id="cb80-8"><a href="#cb80-8" aria-hidden="true" tabindex="-1"></a>        preds <span class="op">=</span> model(xs)</span>
<span id="cb80-9"><a href="#cb80-9" aria-hidden="true" tabindex="-1"></a>        loss <span class="op">=</span> loss_func(preds, ys)</span>
<span id="cb80-10"><a href="#cb80-10" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Print results</span></span>
<span id="cb80-11"><a href="#cb80-11" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> batch <span class="op">//</span> bs <span class="op">//</span> <span class="dv">10</span> <span class="op">==</span> <span class="dv">0</span>: <span class="bu">print</span>(<span class="ss">f"Loss: </span><span class="sc">{</span>loss<span class="sc">.</span>item()<span class="sc">}</span><span class="ss">, accuracy = </span><span class="sc">{</span>accuracy(preds, ys)<span class="sc">.</span>item()<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb80-12"><a href="#cb80-12" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Calculate gradients</span></span>
<span id="cb80-13"><a href="#cb80-13" aria-hidden="true" tabindex="-1"></a>        loss.backward()</span>
<span id="cb80-14"><a href="#cb80-14" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Apply the optimiser</span></span>
<span id="cb80-15"><a href="#cb80-15" aria-hidden="true" tabindex="-1"></a>        opt.step()</span>
<span id="cb80-16"><a href="#cb80-16" aria-hidden="true" tabindex="-1"></a>        opt.zero_grad()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Loss: 2.30017352104187, accuracy = 0.0625
Loss: 2.1758975982666016, accuracy = 0.234375
Loss: 2.199198007583618, accuracy = 0.1875
Loss: 2.005563497543335, accuracy = 0.453125
Loss: 1.9248197078704834, accuracy = 0.359375
Loss: 1.772184133529663, accuracy = 0.578125
Loss: 1.62507963180542, accuracy = 0.546875
Loss: 1.5354200601577759, accuracy = 0.640625
Loss: 1.5023629665374756, accuracy = 0.46875
Loss: 1.6080732345581055, accuracy = 0.421875
Loss: 0.13067957758903503, accuracy = 0.96875
Loss: 0.1198587417602539, accuracy = 0.984375
Loss: 0.2864210307598114, accuracy = 0.921875
Loss: 0.21201932430267334, accuracy = 0.921875
Loss: 0.1917288601398468, accuracy = 0.921875
Loss: 0.04466291889548302, accuracy = 0.96875
Loss: 0.132561594247818, accuracy = 0.96875
Loss: 0.3979755938053131, accuracy = 0.9375
Loss: 0.10060809552669525, accuracy = 0.953125
Loss: 0.3057703375816345, accuracy = 0.9375
Loss: 0.12934750318527222, accuracy = 0.96875
Loss: 0.08657151460647583, accuracy = 0.96875
Loss: 0.21188294887542725, accuracy = 0.90625
Loss: 0.14039435982704163, accuracy = 0.96875
Loss: 0.09377827495336533, accuracy = 0.984375
Loss: 0.0185707900673151, accuracy = 1.0
Loss: 0.081519216299057, accuracy = 0.96875
Loss: 0.32961714267730713, accuracy = 0.953125
Loss: 0.051018428057432175, accuracy = 1.0
Loss: 0.21368607878684998, accuracy = 0.984375</code></pre>
</div>
</div>
<p>The same can be achieved by the use of the pytorch optim library, specifically in this case optim.SGD</p>
<div class="cell" data-execution_count="53">
<div class="sourceCode cell-code" id="cb82"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb82-1"><a href="#cb82-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> torch <span class="im">import</span> optim</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell" data-execution_count="54">
<div class="sourceCode cell-code" id="cb83"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb83-1"><a href="#cb83-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> get_model_and_optimizer():</span>
<span id="cb83-2"><a href="#cb83-2" aria-hidden="true" tabindex="-1"></a>    model <span class="op">=</span> nn.Sequential(nn.Linear(m, nh), nn.ReLU(), nn.Linear(nh, c))</span>
<span id="cb83-3"><a href="#cb83-3" aria-hidden="true" tabindex="-1"></a>    opt <span class="op">=</span> optim.SGD(model.parameters(), lr<span class="op">=</span><span class="fl">0.5</span>)</span>
<span id="cb83-4"><a href="#cb83-4" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> model, opt</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell" data-execution_count="55">
<div class="sourceCode cell-code" id="cb84"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb84-1"><a href="#cb84-1" aria-hidden="true" tabindex="-1"></a>model, opt <span class="op">=</span> get_model_and_optimizer()</span>
<span id="cb84-2"><a href="#cb84-2" aria-hidden="true" tabindex="-1"></a>loss_func(model(xb), yb)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="55">
<pre><code>tensor(2.31, grad_fn=&lt;NllLossBackward0&gt;)</code></pre>
</div>
</div>
<div class="cell" data-execution_count="56">
<div class="sourceCode cell-code" id="cb86"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb86-1"><a href="#cb86-1" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> epoch <span class="kw">in</span> <span class="bu">range</span>(epochs):</span>
<span id="cb86-2"><a href="#cb86-2" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> batch <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">0</span>, n, bs):</span>
<span id="cb86-3"><a href="#cb86-3" aria-hidden="true" tabindex="-1"></a>        <span class="co"># get data</span></span>
<span id="cb86-4"><a href="#cb86-4" aria-hidden="true" tabindex="-1"></a>        s <span class="op">=</span> <span class="bu">slice</span>(batch, <span class="bu">min</span>(n, batch<span class="op">+</span>bs))</span>
<span id="cb86-5"><a href="#cb86-5" aria-hidden="true" tabindex="-1"></a>        xs <span class="op">=</span> x_train[s]</span>
<span id="cb86-6"><a href="#cb86-6" aria-hidden="true" tabindex="-1"></a>        ys <span class="op">=</span> y_train[s]</span>
<span id="cb86-7"><a href="#cb86-7" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Pass data through the model</span></span>
<span id="cb86-8"><a href="#cb86-8" aria-hidden="true" tabindex="-1"></a>        preds <span class="op">=</span> model(xs)</span>
<span id="cb86-9"><a href="#cb86-9" aria-hidden="true" tabindex="-1"></a>        loss <span class="op">=</span> loss_func(preds, ys)</span>
<span id="cb86-10"><a href="#cb86-10" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Print results</span></span>
<span id="cb86-11"><a href="#cb86-11" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> batch <span class="op">//</span> bs <span class="op">//</span> <span class="dv">10</span> <span class="op">==</span> <span class="dv">0</span>: <span class="bu">print</span>(<span class="ss">f"Loss: </span><span class="sc">{</span>loss<span class="sc">.</span>item()<span class="sc">}</span><span class="ss">, accuracy = </span><span class="sc">{</span>accuracy(preds, ys)<span class="sc">.</span>item()<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb86-12"><a href="#cb86-12" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Calculate gradients</span></span>
<span id="cb86-13"><a href="#cb86-13" aria-hidden="true" tabindex="-1"></a>        loss.backward()</span>
<span id="cb86-14"><a href="#cb86-14" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Apply the optimiser</span></span>
<span id="cb86-15"><a href="#cb86-15" aria-hidden="true" tabindex="-1"></a>        opt.step()</span>
<span id="cb86-16"><a href="#cb86-16" aria-hidden="true" tabindex="-1"></a>        opt.zero_grad()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Loss: 2.312685012817383, accuracy = 0.078125
Loss: 2.1906702518463135, accuracy = 0.265625
Loss: 2.1999802589416504, accuracy = 0.1875
Loss: 2.0161678791046143, accuracy = 0.546875
Loss: 1.8945502042770386, accuracy = 0.421875
Loss: 1.7321070432662964, accuracy = 0.640625
Loss: 1.5854045152664185, accuracy = 0.640625
Loss: 1.4941891431808472, accuracy = 0.671875
Loss: 1.4101829528808594, accuracy = 0.546875
Loss: 1.4672781229019165, accuracy = 0.5
Loss: 0.2142210453748703, accuracy = 0.90625
Loss: 0.14814303815364838, accuracy = 0.96875
Loss: 0.32211652398109436, accuracy = 0.90625
Loss: 0.1859450340270996, accuracy = 0.953125
Loss: 0.12843002378940582, accuracy = 0.9375
Loss: 0.05411830171942711, accuracy = 0.984375
Loss: 0.13670694828033447, accuracy = 0.96875
Loss: 0.3170986473560333, accuracy = 0.953125
Loss: 0.10294653475284576, accuracy = 0.953125
Loss: 0.1652507185935974, accuracy = 0.953125
Loss: 0.178289994597435, accuracy = 0.921875
Loss: 0.10243190824985504, accuracy = 0.96875
Loss: 0.2527705132961273, accuracy = 0.921875
Loss: 0.13069084286689758, accuracy = 0.953125
Loss: 0.09603864699602127, accuracy = 0.953125
Loss: 0.02239409275352955, accuracy = 1.0
Loss: 0.1111244335770607, accuracy = 0.96875
Loss: 0.2913336157798767, accuracy = 0.953125
Loss: 0.04398681968450546, accuracy = 1.0
Loss: 0.1203981563448906, accuracy = 0.96875</code></pre>
</div>
</div>
</section>
<section id="dataset-and-dataloader" class="level3">
<h3 class="anchored" data-anchor-id="dataset-and-dataloader">Dataset and DataLoader</h3>
<p>The next part of the development is to make the dataloading more generic, faster and more robust. This is done through the creation of datasets and dataloaders</p>
<section id="dataset" class="level4">
<h4 class="anchored" data-anchor-id="dataset">Dataset</h4>
<p>It’s clunky to iterate through minibatches of x and y values separately:</p>
<div class="sourceCode" id="cb88"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb88-1"><a href="#cb88-1" aria-hidden="true" tabindex="-1"></a>    xb <span class="op">=</span> x_train[s]</span>
<span id="cb88-2"><a href="#cb88-2" aria-hidden="true" tabindex="-1"></a>    yb <span class="op">=</span> y_train[s]</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>Instead, let’s do these two steps together, by introducing a <code>Dataset</code> class:</p>
<div class="sourceCode" id="cb89"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb89-1"><a href="#cb89-1" aria-hidden="true" tabindex="-1"></a>    xb,yb <span class="op">=</span> train_ds[s]</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>In essence the dataset class is a way to robustly link inputs and targets through index values</p>
<div class="cell" data-execution_count="57">
<div class="sourceCode cell-code" id="cb90"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb90-1"><a href="#cb90-1" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> Dataset():</span>
<span id="cb90-2"><a href="#cb90-2" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>, x, y): <span class="va">self</span>.x <span class="op">=</span> x<span class="op">;</span> <span class="va">self</span>.y <span class="op">=</span> y</span>
<span id="cb90-3"><a href="#cb90-3" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__len__</span>(<span class="va">self</span>): <span class="cf">return</span> <span class="bu">len</span>(<span class="va">self</span>.x)</span>
<span id="cb90-4"><a href="#cb90-4" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__getitem__</span>(<span class="va">self</span>, index): <span class="cf">return</span> <span class="va">self</span>.x[index], <span class="va">self</span>.y[index]</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell" data-execution_count="58">
<div class="sourceCode cell-code" id="cb91"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb91-1"><a href="#cb91-1" aria-hidden="true" tabindex="-1"></a>train_ds, valid_ds <span class="op">=</span> Dataset(x_train, y_train), Dataset(x_valid, y_valid)</span>
<span id="cb91-2"><a href="#cb91-2" aria-hidden="true" tabindex="-1"></a><span class="cf">assert</span> <span class="bu">len</span>(x_train) <span class="op">==</span> <span class="bu">len</span>(train_ds)</span>
<span id="cb91-3"><a href="#cb91-3" aria-hidden="true" tabindex="-1"></a><span class="cf">assert</span> <span class="bu">len</span>(x_valid) <span class="op">==</span> <span class="bu">len</span>(valid_ds)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell" data-execution_count="59">
<div class="sourceCode cell-code" id="cb92"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb92-1"><a href="#cb92-1" aria-hidden="true" tabindex="-1"></a>datum_xb, datum_yb <span class="op">=</span> x_train[<span class="dv">0</span>:bs], y_train[<span class="dv">0</span>:bs]</span>
<span id="cb92-2"><a href="#cb92-2" aria-hidden="true" tabindex="-1"></a>xb, yb <span class="op">=</span> train_ds[<span class="dv">0</span>:bs]</span>
<span id="cb92-3"><a href="#cb92-3" aria-hidden="true" tabindex="-1"></a><span class="cf">assert</span> datum_xb.shape <span class="op">==</span> xb.shape</span>
<span id="cb92-4"><a href="#cb92-4" aria-hidden="true" tabindex="-1"></a><span class="cf">assert</span> datum_yb.shape <span class="op">==</span> yb.shape</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell" data-execution_count="60">
<div class="sourceCode cell-code" id="cb93"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb93-1"><a href="#cb93-1" aria-hidden="true" tabindex="-1"></a>xb[<span class="dv">0</span>:<span class="dv">3</span>], yb[<span class="dv">0</span>:<span class="dv">3</span>]</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="60">
<pre><code>(tensor([[0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.]]),
 tensor([5, 0, 4]))</code></pre>
</div>
</div>
<p>Now adapt the training loop to use the dataset</p>
<div class="cell" data-execution_count="61">
<div class="sourceCode cell-code" id="cb95"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb95-1"><a href="#cb95-1" aria-hidden="true" tabindex="-1"></a>model, opt <span class="op">=</span> get_model_and_optimizer()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell" data-execution_count="62">
<div class="sourceCode cell-code" id="cb96"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb96-1"><a href="#cb96-1" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> epoch <span class="kw">in</span> <span class="bu">range</span>(epochs):</span>
<span id="cb96-2"><a href="#cb96-2" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> batch <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">0</span>, n, bs):</span>
<span id="cb96-3"><a href="#cb96-3" aria-hidden="true" tabindex="-1"></a>        <span class="co"># get data</span></span>
<span id="cb96-4"><a href="#cb96-4" aria-hidden="true" tabindex="-1"></a>        xs, ys <span class="op">=</span> train_ds[batch: <span class="bu">min</span>(n, batch<span class="op">+</span>bs)]</span>
<span id="cb96-5"><a href="#cb96-5" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Pass data through the model</span></span>
<span id="cb96-6"><a href="#cb96-6" aria-hidden="true" tabindex="-1"></a>        preds <span class="op">=</span> model(xs)</span>
<span id="cb96-7"><a href="#cb96-7" aria-hidden="true" tabindex="-1"></a>        loss <span class="op">=</span> loss_func(preds, ys)</span>
<span id="cb96-8"><a href="#cb96-8" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Print results</span></span>
<span id="cb96-9"><a href="#cb96-9" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> batch <span class="op">//</span> bs <span class="op">//</span> <span class="dv">10</span> <span class="op">==</span> <span class="dv">0</span>: <span class="bu">print</span>(<span class="ss">f"Loss: </span><span class="sc">{</span>loss<span class="sc">.</span>item()<span class="sc">}</span><span class="ss">, accuracy = </span><span class="sc">{</span>accuracy(preds, ys)<span class="sc">.</span>item()<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb96-10"><a href="#cb96-10" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Calculate gradients</span></span>
<span id="cb96-11"><a href="#cb96-11" aria-hidden="true" tabindex="-1"></a>        loss.backward()</span>
<span id="cb96-12"><a href="#cb96-12" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Apply the optimiser</span></span>
<span id="cb96-13"><a href="#cb96-13" aria-hidden="true" tabindex="-1"></a>        opt.step()</span>
<span id="cb96-14"><a href="#cb96-14" aria-hidden="true" tabindex="-1"></a>        opt.zero_grad()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Loss: 2.2979648113250732, accuracy = 0.09375
Loss: 2.1677284240722656, accuracy = 0.40625
Loss: 2.192817211151123, accuracy = 0.171875
Loss: 1.992324709892273, accuracy = 0.5
Loss: 1.8881453275680542, accuracy = 0.5
Loss: 1.6967313289642334, accuracy = 0.703125
Loss: 1.6032072305679321, accuracy = 0.578125
Loss: 1.5213433504104614, accuracy = 0.65625
Loss: 1.4437696933746338, accuracy = 0.46875
Loss: 1.5202784538269043, accuracy = 0.53125
Loss: 0.2117222249507904, accuracy = 0.953125
Loss: 0.15176746249198914, accuracy = 0.96875
Loss: 0.2823413908481598, accuracy = 0.921875
Loss: 0.1383940577507019, accuracy = 0.953125
Loss: 0.13499413430690765, accuracy = 0.921875
Loss: 0.04650742560625076, accuracy = 0.984375
Loss: 0.12225606292486191, accuracy = 0.953125
Loss: 0.31971240043640137, accuracy = 0.953125
Loss: 0.07508628815412521, accuracy = 0.96875
Loss: 0.22737926244735718, accuracy = 0.96875
Loss: 0.1587153971195221, accuracy = 0.921875
Loss: 0.12036815285682678, accuracy = 0.984375
Loss: 0.27983012795448303, accuracy = 0.90625
Loss: 0.07115809619426727, accuracy = 0.984375
Loss: 0.10483404994010925, accuracy = 0.9375
Loss: 0.025242304429411888, accuracy = 1.0
Loss: 0.09612352401018143, accuracy = 0.953125
Loss: 0.2911374866962433, accuracy = 0.953125
Loss: 0.05527857318520546, accuracy = 0.984375
Loss: 0.16760416328907013, accuracy = 0.984375</code></pre>
</div>
</div>
</section>
<section id="dataloader" class="level4">
<h4 class="anchored" data-anchor-id="dataloader">DataLoader</h4>
<p>The dataloader takes responsibility for which data to load, which allows choices to me made such as whether to sample randomly or sequentially etc. Effectively the dataloader is an iterator that will feed data one batch at a time until the dataset is exhausted.</p>
<p>In the example below a simple sequential sampler it implemented, others will be added later</p>
<div class="cell" data-execution_count="63">
<div class="sourceCode cell-code" id="cb98"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb98-1"><a href="#cb98-1" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> DataLoader():</span>
<span id="cb98-2"><a href="#cb98-2" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>, dataset, bs):</span>
<span id="cb98-3"><a href="#cb98-3" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.dataset, <span class="va">self</span>.bs <span class="op">=</span> dataset, bs</span>
<span id="cb98-4"><a href="#cb98-4" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb98-5"><a href="#cb98-5" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__iter__</span>(<span class="va">self</span>):</span>
<span id="cb98-6"><a href="#cb98-6" aria-hidden="true" tabindex="-1"></a>        <span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">0</span>, <span class="bu">len</span>(<span class="va">self</span>.dataset), <span class="va">self</span>.bs):</span>
<span id="cb98-7"><a href="#cb98-7" aria-hidden="true" tabindex="-1"></a>            <span class="cf">yield</span> <span class="va">self</span>.dataset[i:<span class="bu">min</span>(i<span class="op">+</span><span class="va">self</span>.bs, <span class="bu">len</span>(<span class="va">self</span>.dataset))]</span>
<span id="cb98-8"><a href="#cb98-8" aria-hidden="true" tabindex="-1"></a>    </span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell" data-execution_count="64">
<div class="sourceCode cell-code" id="cb99"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb99-1"><a href="#cb99-1" aria-hidden="true" tabindex="-1"></a><span class="bu">len</span>(train_ds)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="64">
<pre><code>50000</code></pre>
</div>
</div>
<div class="cell" data-execution_count="65">
<div class="sourceCode cell-code" id="cb101"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb101-1"><a href="#cb101-1" aria-hidden="true" tabindex="-1"></a>train_dl <span class="op">=</span> DataLoader(train_ds, bs)</span>
<span id="cb101-2"><a href="#cb101-2" aria-hidden="true" tabindex="-1"></a>valid_dl <span class="op">=</span> DataLoader(valid_ds, bs)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell" data-execution_count="66">
<div class="sourceCode cell-code" id="cb102"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb102-1"><a href="#cb102-1" aria-hidden="true" tabindex="-1"></a>xb, yb <span class="op">=</span> <span class="bu">next</span>(<span class="bu">iter</span>(train_dl))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell" data-execution_count="67">
<div class="sourceCode cell-code" id="cb103"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb103-1"><a href="#cb103-1" aria-hidden="true" tabindex="-1"></a>xb.shape, yb.shape</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="67">
<pre><code>(torch.Size([64, 784]), torch.Size([64]))</code></pre>
</div>
</div>
<div class="cell" data-execution_count="68">
<div class="sourceCode cell-code" id="cb105"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb105-1"><a href="#cb105-1" aria-hidden="true" tabindex="-1"></a>plt.imshow(xb[<span class="dv">0</span>].view(<span class="dv">28</span>,<span class="dv">28</span>))</span>
<span id="cb105-2"><a href="#cb105-2" aria-hidden="true" tabindex="-1"></a>yb[<span class="dv">0</span>]</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="68">
<pre><code>tensor(5)</code></pre>
</div>
<div class="cell-output cell-output-display">
<p><img src="04_dataloaders_optimisers_training_files/figure-html/cell-69-output-2.png" class="img-fluid"></p>
</div>
</div>
<p>Now implement a training loop with the dataloader</p>
<div class="cell" data-execution_count="69">
<div class="sourceCode cell-code" id="cb107"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb107-1"><a href="#cb107-1" aria-hidden="true" tabindex="-1"></a>model, opt <span class="op">=</span> get_model_and_optimizer()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Now create a function for the fit process since this will be used several times</p>
<div class="cell" data-execution_count="70">
<div class="sourceCode cell-code" id="cb108"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb108-1"><a href="#cb108-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> fit():</span>
<span id="cb108-2"><a href="#cb108-2" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> epoch <span class="kw">in</span> <span class="bu">range</span>(epochs):</span>
<span id="cb108-3"><a href="#cb108-3" aria-hidden="true" tabindex="-1"></a>        <span class="cf">for</span> xb, yb <span class="kw">in</span> train_dl:</span>
<span id="cb108-4"><a href="#cb108-4" aria-hidden="true" tabindex="-1"></a>            <span class="co"># Pass data through the model</span></span>
<span id="cb108-5"><a href="#cb108-5" aria-hidden="true" tabindex="-1"></a>            preds <span class="op">=</span> model(xb)</span>
<span id="cb108-6"><a href="#cb108-6" aria-hidden="true" tabindex="-1"></a>            loss <span class="op">=</span> loss_func(preds, yb)</span>
<span id="cb108-7"><a href="#cb108-7" aria-hidden="true" tabindex="-1"></a>            <span class="co"># Calculate gradients</span></span>
<span id="cb108-8"><a href="#cb108-8" aria-hidden="true" tabindex="-1"></a>            loss.backward()</span>
<span id="cb108-9"><a href="#cb108-9" aria-hidden="true" tabindex="-1"></a>            <span class="co"># Apply the optimiser</span></span>
<span id="cb108-10"><a href="#cb108-10" aria-hidden="true" tabindex="-1"></a>            opt.step()</span>
<span id="cb108-11"><a href="#cb108-11" aria-hidden="true" tabindex="-1"></a>            opt.zero_grad()</span>
<span id="cb108-12"><a href="#cb108-12" aria-hidden="true" tabindex="-1"></a>        <span class="bu">print</span>(<span class="ss">f'After epoch </span><span class="sc">{</span>epoch<span class="sc">}</span><span class="ss">, batch loss is: </span><span class="sc">{</span>loss<span class="sc">.</span>item()<span class="sc">}</span><span class="ss">'</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell" data-execution_count="71">
<div class="sourceCode cell-code" id="cb109"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb109-1"><a href="#cb109-1" aria-hidden="true" tabindex="-1"></a>fit()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>After epoch 0, batch loss is: 0.3089807331562042
After epoch 1, batch loss is: 0.19600419700145721
After epoch 2, batch loss is: 0.10103154182434082</code></pre>
</div>
</div>
<div class="cell" data-execution_count="72">
<div class="sourceCode cell-code" id="cb111"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb111-1"><a href="#cb111-1" aria-hidden="true" tabindex="-1"></a>loss_func(model(xb), yb), accuracy(model(xb), yb)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="72">
<pre><code>(tensor(0.17, grad_fn=&lt;NllLossBackward0&gt;), tensor(0.94))</code></pre>
</div>
</div>
<div class="cell" data-execution_count="73">
<div class="sourceCode cell-code" id="cb113"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb113-1"><a href="#cb113-1" aria-hidden="true" tabindex="-1"></a>xb.shape</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="73">
<pre><code>torch.Size([64, 784])</code></pre>
</div>
</div>
</section>
</section>
</section>
<section id="adding-in-different-sampling-methods" class="level2">
<h2 class="anchored" data-anchor-id="adding-in-different-sampling-methods">Adding in different sampling methods</h2>
<p>To enable random or linear sampling a class is added to manage the sampling. This will now be developed. The inputs to the sampler need to be the dataset and a flag to indicate the type of sampling. The return should be the same dataset either shuffled or processed as necessary. This could be done upon just the item index values or the whole dataset could be processed and returned. In this case the item indexies are returned as a list as requested by the iter call</p>
<p>I’m not sure why yield is not used here - something to check up on</p>
<div class="cell" data-execution_count="74">
<div class="sourceCode cell-code" id="cb115"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb115-1"><a href="#cb115-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> random</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell" data-execution_count="75">
<div class="sourceCode cell-code" id="cb116"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb116-1"><a href="#cb116-1" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> Sampler():</span>
<span id="cb116-2"><a href="#cb116-2" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>, ds, shuffle<span class="op">=</span><span class="va">False</span>):</span>
<span id="cb116-3"><a href="#cb116-3" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.n <span class="op">=</span> <span class="bu">len</span>(ds)</span>
<span id="cb116-4"><a href="#cb116-4" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.ds <span class="op">=</span> ds</span>
<span id="cb116-5"><a href="#cb116-5" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.shuffle <span class="op">=</span> shuffle</span>
<span id="cb116-6"><a href="#cb116-6" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb116-7"><a href="#cb116-7" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__iter__</span>(<span class="va">self</span>):</span>
<span id="cb116-8"><a href="#cb116-8" aria-hidden="true" tabindex="-1"></a>        indecies <span class="op">=</span> <span class="bu">list</span>(<span class="bu">range</span>(<span class="va">self</span>.n))</span>
<span id="cb116-9"><a href="#cb116-9" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> <span class="va">self</span>.shuffle:</span>
<span id="cb116-10"><a href="#cb116-10" aria-hidden="true" tabindex="-1"></a>            random.shuffle(indecies)</span>
<span id="cb116-11"><a href="#cb116-11" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> <span class="bu">iter</span>(indecies)</span>
<span id="cb116-12"><a href="#cb116-12" aria-hidden="true" tabindex="-1"></a>        </span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell" data-execution_count="76">
<div class="sourceCode cell-code" id="cb117"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb117-1"><a href="#cb117-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> itertools <span class="im">import</span> islice</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell" data-execution_count="77">
<div class="sourceCode cell-code" id="cb118"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb118-1"><a href="#cb118-1" aria-hidden="true" tabindex="-1"></a>sampler <span class="op">=</span> Sampler(x_train, shuffle<span class="op">=</span><span class="va">False</span>)</span>
<span id="cb118-2"><a href="#cb118-2" aria-hidden="true" tabindex="-1"></a>iterator <span class="op">=</span> <span class="bu">iter</span>(sampler)</span>
<span id="cb118-3"><a href="#cb118-3" aria-hidden="true" tabindex="-1"></a>ids <span class="op">=</span> []</span>
<span id="cb118-4"><a href="#cb118-4" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">5</span>): ids.append(<span class="bu">next</span>(iterator))</span>
<span id="cb118-5"><a href="#cb118-5" aria-hidden="true" tabindex="-1"></a>ids</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="77">
<pre><code>[0, 1, 2, 3, 4]</code></pre>
</div>
</div>
<p>This is returning things one item at a time from the iterator. It is possible to use islice to generate a range of items. Note that since this iterator has already returned five entries it will supply the next 5, it doesn’t start from to front of the list unless a new iterator is created</p>
<div class="cell" data-execution_count="78">
<div class="sourceCode cell-code" id="cb120"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb120-1"><a href="#cb120-1" aria-hidden="true" tabindex="-1"></a>ids <span class="op">=</span> <span class="bu">list</span>(islice(iterator, <span class="dv">0</span>, <span class="dv">5</span>))</span>
<span id="cb120-2"><a href="#cb120-2" aria-hidden="true" tabindex="-1"></a>ids</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="78">
<pre><code>[5, 6, 7, 8, 9]</code></pre>
</div>
</div>
<p>When the random flag is set to true then</p>
<div class="cell" data-execution_count="79">
<div class="sourceCode cell-code" id="cb122"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb122-1"><a href="#cb122-1" aria-hidden="true" tabindex="-1"></a>sampler <span class="op">=</span> Sampler(x_train, shuffle<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb122-2"><a href="#cb122-2" aria-hidden="true" tabindex="-1"></a><span class="bu">list</span>(islice(sampler, <span class="dv">0</span>, <span class="dv">10</span>))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="79">
<pre><code>[19149, 3623, 33271, 45722, 34626, 44572, 33273, 31591, 1328, 44705]</code></pre>
</div>
</div>
<div class="cell" data-execution_count="80">
<div class="sourceCode cell-code" id="cb124"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb124-1"><a href="#cb124-1" aria-hidden="true" tabindex="-1"></a>sampler_v <span class="op">=</span> Sampler(x_valid, shuffle<span class="op">=</span><span class="va">False</span>)</span>
<span id="cb124-2"><a href="#cb124-2" aria-hidden="true" tabindex="-1"></a><span class="bu">list</span>(islice(sampler_v, <span class="dv">0</span>, <span class="dv">10</span>))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="80">
<pre><code>[0, 1, 2, 3, 4, 5, 6, 7, 8, 9]</code></pre>
</div>
</div>
<p>Having proven the basics of the sampler the fastcore library will be used to create a batch sampler. Two fastcore methods are used: 1. store_attr. This simply saves any parameters supplied as class properties with the same name as the supplied parameter 2. chunked. This returns batches of indecies from an iterator of user defined size with the option to specity whether to drop the last chunk if not the batch size, and also to provide only a defined number of chunks (useful to use a part of a dataset when get things working)</p>
<div class="cell" data-execution_count="81">
<div class="sourceCode cell-code" id="cb126"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb126-1"><a href="#cb126-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> fastcore.<span class="bu">all</span> <span class="im">as</span> fc</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>The class BatchSampler is require to take as input the dataset, batch size, the sampler, and whether to drop the last batch if not the correct size. In this case the dataset is already embedded into the sampler and hence does not need to be added separately. The output should be an iterator returning batches of indecies</p>
<div class="cell" data-execution_count="82">
<div class="sourceCode cell-code" id="cb127"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb127-1"><a href="#cb127-1" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> BatchSampler:</span>
<span id="cb127-2"><a href="#cb127-2" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>, sampler, bs<span class="op">=</span><span class="dv">16</span>, drop_last<span class="op">=</span><span class="va">False</span>):</span>
<span id="cb127-3"><a href="#cb127-3" aria-hidden="true" tabindex="-1"></a>        fc.store_attr()</span>
<span id="cb127-4"><a href="#cb127-4" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb127-5"><a href="#cb127-5" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__iter__</span>(<span class="va">self</span>, ):</span>
<span id="cb127-6"><a href="#cb127-6" aria-hidden="true" tabindex="-1"></a>        <span class="cf">yield</span> <span class="cf">from</span> fc.chunked(<span class="bu">iter</span>(<span class="va">self</span>.sampler), chunk_sz<span class="op">=</span><span class="va">self</span>.bs, drop_last<span class="op">=</span><span class="va">self</span>.drop_last)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell" data-execution_count="83">
<div class="sourceCode cell-code" id="cb128"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb128-1"><a href="#cb128-1" aria-hidden="true" tabindex="-1"></a>batches <span class="op">=</span> BatchSampler(sampler, bs<span class="op">=</span><span class="dv">4</span>, drop_last<span class="op">=</span><span class="va">False</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell" data-execution_count="84">
<div class="sourceCode cell-code" id="cb129"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb129-1"><a href="#cb129-1" aria-hidden="true" tabindex="-1"></a><span class="bu">next</span>(<span class="bu">iter</span>(batches))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="84">
<pre><code>[25976, 3805, 2452, 7221]</code></pre>
</div>
</div>
<div class="cell" data-execution_count="85">
<div class="sourceCode cell-code" id="cb131"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb131-1"><a href="#cb131-1" aria-hidden="true" tabindex="-1"></a><span class="bu">list</span>(islice(batches, <span class="dv">5</span>))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="85">
<pre><code>[[43889, 38760, 1660, 43812],
 [19474, 27881, 1648, 5994],
 [43292, 20760, 47927, 46678],
 [16207, 19001, 31035, 2216],
 [21505, 234, 47366, 36409]]</code></pre>
</div>
</div>
<p>BatchSampler will provide a list of ids with which to make up the batch. The Sampler will then return the individual input data and targets for each id. The then have to collate the inputs and targets into torch arrays for processing.</p>
<p>This collation and stacking of data is done by a collate function</p>
<p>We now need a collate method to take the samples and convert them into a stacked tensor or inputs and outputs</p>
<p>Collator inputs: list of tuples of input value pairs outputs: tuple of input and target values as torch tensors</p>
<div class="cell" data-execution_count="86">
<div class="sourceCode cell-code" id="cb133"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb133-1"><a href="#cb133-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> collate(b):</span>
<span id="cb133-2"><a href="#cb133-2" aria-hidden="true" tabindex="-1"></a>    <span class="co"># the * means that multiple items will be received, which effectively means the list is taken an item</span></span>
<span id="cb133-3"><a href="#cb133-3" aria-hidden="true" tabindex="-1"></a>    <span class="co"># at a time</span></span>
<span id="cb133-4"><a href="#cb133-4" aria-hidden="true" tabindex="-1"></a>    xb, yb <span class="op">=</span> <span class="bu">zip</span>(<span class="op">*</span>b)</span>
<span id="cb133-5"><a href="#cb133-5" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> (torch.stack(xb), torch.stack(yb))</span>
<span id="cb133-6"><a href="#cb133-6" aria-hidden="true" tabindex="-1"></a>    </span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell" data-execution_count="87">
<div class="sourceCode cell-code" id="cb134"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb134-1"><a href="#cb134-1" aria-hidden="true" tabindex="-1"></a>bi <span class="op">=</span> [train_ds[<span class="dv">0</span>], train_ds[<span class="dv">1</span>], train_ds[<span class="dv">2</span>]]</span>
<span id="cb134-2"><a href="#cb134-2" aria-hidden="true" tabindex="-1"></a>collate(bi)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="87">
<pre><code>(tensor([[0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.]]),
 tensor([5, 0, 4]))</code></pre>
</div>
</div>
<section id="finally-create-a-full-dataloader-using-the-above-components" class="level3">
<h3 class="anchored" data-anchor-id="finally-create-a-full-dataloader-using-the-above-components">Finally create a full dataloader using the above components</h3>
<p>inputs:dataset, batch size, sampling method to use, whether to use last batch</p>
<p>outputs: tuple of stacked array of inputs and targets</p>
<p>methods: initiation - setup the dataset, sampling method, batch size, options iter - return a batch of data as a tuple</p>
<div class="cell" data-execution_count="88">
<div class="sourceCode cell-code" id="cb136"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb136-1"><a href="#cb136-1" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> DataLoader():</span>
<span id="cb136-2"><a href="#cb136-2" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>, dataset, collate_fn<span class="op">=</span>collate, bs<span class="op">=</span><span class="dv">64</span>, shuffle<span class="op">=</span><span class="va">False</span>, drop_last<span class="op">=</span><span class="va">False</span>):</span>
<span id="cb136-3"><a href="#cb136-3" aria-hidden="true" tabindex="-1"></a>        fc.store_attr()</span>
<span id="cb136-4"><a href="#cb136-4" aria-hidden="true" tabindex="-1"></a>        sampler <span class="op">=</span> Sampler(ds<span class="op">=</span>dataset, shuffle<span class="op">=</span>shuffle)</span>
<span id="cb136-5"><a href="#cb136-5" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.batch_sampler <span class="op">=</span> BatchSampler(sampler, bs, drop_last)</span>
<span id="cb136-6"><a href="#cb136-6" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb136-7"><a href="#cb136-7" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__iter__</span>(<span class="va">self</span>):</span>
<span id="cb136-8"><a href="#cb136-8" aria-hidden="true" tabindex="-1"></a>        <span class="cf">yield</span> <span class="cf">from</span> (<span class="va">self</span>.collate_fn(<span class="va">self</span>.dataset[i] <span class="cf">for</span> i <span class="kw">in</span> b) <span class="cf">for</span> b <span class="kw">in</span> <span class="va">self</span>.batch_sampler)</span>
<span id="cb136-9"><a href="#cb136-9" aria-hidden="true" tabindex="-1"></a>        </span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell" data-execution_count="89">
<div class="sourceCode cell-code" id="cb137"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb137-1"><a href="#cb137-1" aria-hidden="true" tabindex="-1"></a>train_dl <span class="op">=</span> DataLoader(train_ds, collate, bs<span class="op">=</span><span class="dv">64</span>, shuffle<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb137-2"><a href="#cb137-2" aria-hidden="true" tabindex="-1"></a>valid_dl <span class="op">=</span> DataLoader(valid_ds, collate, bs<span class="op">=</span><span class="dv">64</span>, shuffle<span class="op">=</span><span class="va">False</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell" data-execution_count="90">
<div class="sourceCode cell-code" id="cb138"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb138-1"><a href="#cb138-1" aria-hidden="true" tabindex="-1"></a>train_batch <span class="op">=</span> <span class="bu">next</span>(<span class="bu">iter</span>(train_dl))</span>
<span id="cb138-2"><a href="#cb138-2" aria-hidden="true" tabindex="-1"></a>train_batch[<span class="dv">0</span>].shape, train_batch[<span class="dv">1</span>].shape</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="90">
<pre><code>(torch.Size([64, 784]), torch.Size([64]))</code></pre>
</div>
</div>
<div class="cell" data-execution_count="91">
<div class="sourceCode cell-code" id="cb140"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb140-1"><a href="#cb140-1" aria-hidden="true" tabindex="-1"></a>xb,yb <span class="op">=</span> <span class="bu">next</span>(<span class="bu">iter</span>(valid_dl))</span>
<span id="cb140-2"><a href="#cb140-2" aria-hidden="true" tabindex="-1"></a>xb.shape</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="91">
<pre><code>torch.Size([64, 784])</code></pre>
</div>
</div>
<div class="cell" data-execution_count="92">
<div class="sourceCode cell-code" id="cb142"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb142-1"><a href="#cb142-1" aria-hidden="true" tabindex="-1"></a>xb,yb <span class="op">=</span> <span class="bu">next</span>(<span class="bu">iter</span>(valid_dl))</span>
<span id="cb142-2"><a href="#cb142-2" aria-hidden="true" tabindex="-1"></a>plt.imshow(xb[<span class="dv">0</span>].view(<span class="dv">28</span>,<span class="dv">28</span>))</span>
<span id="cb142-3"><a href="#cb142-3" aria-hidden="true" tabindex="-1"></a>yb[<span class="dv">0</span>]</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="92">
<pre><code>tensor(3)</code></pre>
</div>
<div class="cell-output cell-output-display">
<p><img src="04_dataloaders_optimisers_training_files/figure-html/cell-93-output-2.png" class="img-fluid"></p>
</div>
</div>
<div class="cell" data-execution_count="93">
<div class="sourceCode cell-code" id="cb144"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb144-1"><a href="#cb144-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Check the accuracy of the model when trained with the Dataloader</span></span>
<span id="cb144-2"><a href="#cb144-2" aria-hidden="true" tabindex="-1"></a>model,opt <span class="op">=</span> get_model_and_optimizer()</span>
<span id="cb144-3"><a href="#cb144-3" aria-hidden="true" tabindex="-1"></a>fit()</span>
<span id="cb144-4"><a href="#cb144-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb144-5"><a href="#cb144-5" aria-hidden="true" tabindex="-1"></a>loss_func(model(xb), yb), accuracy(model(xb), yb)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>After epoch 0, batch loss is: 0.05507710948586464
After epoch 1, batch loss is: 0.055910542607307434
After epoch 2, batch loss is: 0.07595346868038177</code></pre>
</div>
<div class="cell-output cell-output-display" data-execution_count="93">
<pre><code>(tensor(0.10, grad_fn=&lt;NllLossBackward0&gt;), tensor(0.97))</code></pre>
</div>
</div>
</section>
</section>
<section id="multiprocesssing-dataloader" class="level2">
<h2 class="anchored" data-anchor-id="multiprocesssing-dataloader">Multiprocesssing DataLoader</h2>
<p>Data loading is often a constraint in terms or time to process a job. Fortunately this is a task that lends itself to multi-processing and hence it makes sense to apply this.</p>
<p>Pytorch provide a multi-processing library and that is what will be used here.</p>
<p>The way it will be done is that the above library will provide a pool or workers, the number of which can be defined. Each worker can then be asked to load a batch of data. The batches returned will be returned as requested</p>
<div class="cell" data-execution_count="94">
<div class="sourceCode cell-code" id="cb147"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb147-1"><a href="#cb147-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> torch.multiprocessing <span class="im">as</span> mp</span>
<span id="cb147-2"><a href="#cb147-2" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> fastcore.basics <span class="im">import</span> store_attr</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>The way a dataset returns values based upon the index uses the getitem dunder as can be seen here</p>
<div class="cell" data-execution_count="95">
<div class="sourceCode cell-code" id="cb148"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb148-1"><a href="#cb148-1" aria-hidden="true" tabindex="-1"></a>train_ds.<span class="fu">__getitem__</span>([[<span class="dv">3</span>,<span class="dv">5</span>,<span class="dv">8</span>,<span class="dv">10</span>]])</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="95">
<pre><code>(tensor([[0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.]]),
 tensor([1, 2, 1, 3]))</code></pre>
</div>
</div>
<div class="cell" data-execution_count="96">
<div class="sourceCode cell-code" id="cb150"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb150-1"><a href="#cb150-1" aria-hidden="true" tabindex="-1"></a>train_ds.<span class="fu">__getitem__</span>([<span class="dv">3</span>,<span class="dv">5</span>,<span class="dv">8</span>,<span class="dv">10</span>])</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="96">
<pre><code>(tensor([[0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.]]),
 tensor([1, 2, 1, 3]))</code></pre>
</div>
</div>
<p>It is possible to use the map function to split individual groups of items as below</p>
<div class="cell" data-execution_count="97">
<div class="sourceCode cell-code" id="cb152"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb152-1"><a href="#cb152-1" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> o <span class="kw">in</span> <span class="bu">map</span>(train_ds.<span class="fu">__getitem__</span>, [[<span class="dv">3</span>,<span class="dv">5</span>], [<span class="dv">8</span>,<span class="dv">10</span>]]):</span>
<span id="cb152-2"><a href="#cb152-2" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(o)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>(tensor([[0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.]]), tensor([1, 2]))
(tensor([[0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.]]), tensor([1, 3]))</code></pre>
</div>
</div>
<p>The dataloader can then be modified so that each worker in a pool loads a batch and return it when requested. Note that it appears that the collate function is not needed here since the way in which the batch sampler passes a list of indecies results in an array of values being returned.</p>
<div class="cell" data-execution_count="98">
<div class="sourceCode cell-code" id="cb154"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb154-1"><a href="#cb154-1" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> DataLoader():</span>
<span id="cb154-2"><a href="#cb154-2" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>, dataset, bs<span class="op">=</span><span class="dv">64</span>, shuffle<span class="op">=</span><span class="va">False</span>, drop_last<span class="op">=</span><span class="va">False</span>, num_workers<span class="op">=</span><span class="dv">1</span>):</span>
<span id="cb154-3"><a href="#cb154-3" aria-hidden="true" tabindex="-1"></a>        fc.store_attr()</span>
<span id="cb154-4"><a href="#cb154-4" aria-hidden="true" tabindex="-1"></a>        sampler <span class="op">=</span> Sampler(ds<span class="op">=</span>dataset, shuffle<span class="op">=</span>shuffle)</span>
<span id="cb154-5"><a href="#cb154-5" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.batch_sampler <span class="op">=</span> BatchSampler(sampler, bs, drop_last)</span>
<span id="cb154-6"><a href="#cb154-6" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb154-7"><a href="#cb154-7" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__iter__</span>(<span class="va">self</span>):</span>
<span id="cb154-8"><a href="#cb154-8" aria-hidden="true" tabindex="-1"></a>        <span class="cf">with</span> mp.Pool(<span class="va">self</span>.num_workers) <span class="im">as</span> ex:</span>
<span id="cb154-9"><a href="#cb154-9" aria-hidden="true" tabindex="-1"></a>            <span class="cf">yield</span> <span class="cf">from</span> ex.<span class="bu">map</span>(<span class="va">self</span>.dataset.<span class="fu">__getitem__</span>, <span class="bu">iter</span>(<span class="va">self</span>.batch_sampler))</span>
<span id="cb154-10"><a href="#cb154-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb154-11"><a href="#cb154-11" aria-hidden="true" tabindex="-1"></a>        </span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell" data-execution_count="99">
<div class="sourceCode cell-code" id="cb155"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb155-1"><a href="#cb155-1" aria-hidden="true" tabindex="-1"></a>train_dl <span class="op">=</span> DataLoader(train_ds, bs<span class="op">=</span><span class="dv">64</span>, shuffle<span class="op">=</span><span class="va">True</span>, num_workers<span class="op">=</span><span class="dv">2</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell" data-execution_count="100">
<div class="sourceCode cell-code" id="cb156"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb156-1"><a href="#cb156-1" aria-hidden="true" tabindex="-1"></a>it <span class="op">=</span> <span class="bu">iter</span>(train_dl)</span>
<span id="cb156-2"><a href="#cb156-2" aria-hidden="true" tabindex="-1"></a>res <span class="op">=</span> <span class="bu">next</span>(it)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell" data-execution_count="101">
<div class="sourceCode cell-code" id="cb157"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb157-1"><a href="#cb157-1" aria-hidden="true" tabindex="-1"></a>xb, yb <span class="op">=</span> <span class="bu">next</span>(it)</span>
<span id="cb157-2"><a href="#cb157-2" aria-hidden="true" tabindex="-1"></a>xb.shape, yb.shape</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="101">
<pre><code>(torch.Size([64, 784]), torch.Size([64]))</code></pre>
</div>
</div>
<div class="cell" data-execution_count="102">
<div class="sourceCode cell-code" id="cb159"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb159-1"><a href="#cb159-1" aria-hidden="true" tabindex="-1"></a><span class="bu">len</span>(res),res[<span class="dv">0</span>].shape</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="102">
<pre><code>(2, torch.Size([64, 784]))</code></pre>
</div>
</div>
</section>
<section id="pytorch-dataloader" class="level2">
<h2 class="anchored" data-anchor-id="pytorch-dataloader">Pytorch DataLoader</h2>
<div class="cell" data-execution_count="103">
<div class="sourceCode cell-code" id="cb161"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb161-1"><a href="#cb161-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> torch.utils.data <span class="im">import</span> DataLoader, SequentialSampler, RandomSampler, BatchSampler</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Steps to follow: 1. Create batch sampler 2. create dataloader (with multi worker) 3. Train model entirely using PyTorch 4.</p>
<div class="cell" data-execution_count="104">
<div class="sourceCode cell-code" id="cb162"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb162-1"><a href="#cb162-1" aria-hidden="true" tabindex="-1"></a>train_bs <span class="op">=</span> BatchSampler(RandomSampler(train_ds), batch_size<span class="op">=</span>bs, drop_last<span class="op">=</span><span class="va">False</span>)</span>
<span id="cb162-2"><a href="#cb162-2" aria-hidden="true" tabindex="-1"></a>valid_bs <span class="op">=</span> BatchSampler(SequentialSampler(valid_ds), batch_size<span class="op">=</span>bs, drop_last<span class="op">=</span><span class="va">False</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell" data-execution_count="105">
<div class="sourceCode cell-code" id="cb163"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb163-1"><a href="#cb163-1" aria-hidden="true" tabindex="-1"></a><span class="co"># In this case the collate function is not required</span></span>
<span id="cb163-2"><a href="#cb163-2" aria-hidden="true" tabindex="-1"></a>train_dl <span class="op">=</span> DataLoader(train_ds, batch_sampler<span class="op">=</span>train_bs, num_workers<span class="op">=</span><span class="dv">4</span>, collate_fn<span class="op">=</span>collate)</span>
<span id="cb163-3"><a href="#cb163-3" aria-hidden="true" tabindex="-1"></a>valid_dl <span class="op">=</span> DataLoader(valid_ds, batch_sampler<span class="op">=</span>valid_bs, num_workers<span class="op">=</span><span class="dv">4</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>In this case the collate function is not necessary as the dataset will already do this, as was shown above by the way a list of items returns stacked arrays. Allowing Pytorch to autogenerate teh samplers as well then this can all be simplified to</p>
<div class="cell" data-execution_count="106">
<div class="sourceCode cell-code" id="cb164"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb164-1"><a href="#cb164-1" aria-hidden="true" tabindex="-1"></a>train_dl <span class="op">=</span> DataLoader(train_ds, batch_size<span class="op">=</span>bs, shuffle<span class="op">=</span><span class="va">True</span>, drop_last<span class="op">=</span><span class="va">True</span>, num_workers<span class="op">=</span><span class="dv">4</span>)</span>
<span id="cb164-2"><a href="#cb164-2" aria-hidden="true" tabindex="-1"></a>valid_dl <span class="op">=</span> DataLoader(valid_ds, batch_size<span class="op">=</span>bs, shuffle<span class="op">=</span><span class="va">False</span>, drop_last<span class="op">=</span><span class="va">False</span>, num_workers<span class="op">=</span><span class="dv">4</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Check accuracy as usual</p>
<div class="cell" data-execution_count="107">
<div class="sourceCode cell-code" id="cb165"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb165-1"><a href="#cb165-1" aria-hidden="true" tabindex="-1"></a>model,opt <span class="op">=</span> get_model_and_optimizer()</span>
<span id="cb165-2"><a href="#cb165-2" aria-hidden="true" tabindex="-1"></a>fit()</span>
<span id="cb165-3"><a href="#cb165-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb165-4"><a href="#cb165-4" aria-hidden="true" tabindex="-1"></a>loss_func(model(xb), yb), accuracy(model(xb), yb)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>After epoch 0, batch loss is: 0.3000752925872803
After epoch 1, batch loss is: 0.034155331552028656
After epoch 2, batch loss is: 0.07146771252155304</code></pre>
</div>
<div class="cell-output cell-output-display" data-execution_count="107">
<pre><code>(tensor(0.12, grad_fn=&lt;NllLossBackward0&gt;), tensor(0.97))</code></pre>
</div>
</div>
</section>
<section id="validation" class="level2">
<h2 class="anchored" data-anchor-id="validation">Validation</h2>
<p>It is good (essential) practice to have a validation set and to check the accuracu of the model periodically, such as at the end of each epoch.</p>
<p>Before calling the validation dataset it is necessary to put the model into eval mode, which avoids issues with batchnorm and dropout layers, where different setting are used for training</p>
<p>Create an update fit routine which calculates and prints out loss and accuracy at the end of each epoch. As input define the number of epochs, the model to use, the loss function, the optimiser and the train and test dataloasers</p>
<div class="cell" data-execution_count="108">
<div class="sourceCode cell-code" id="cb168"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb168-1"><a href="#cb168-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> fit(epochs, model, loss_func, opt, train_dl, valid_dl):</span>
<span id="cb168-2"><a href="#cb168-2" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Loop through the epochs</span></span>
<span id="cb168-3"><a href="#cb168-3" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> epoch <span class="kw">in</span> <span class="bu">range</span>(epochs):</span>
<span id="cb168-4"><a href="#cb168-4" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Set model into training mode</span></span>
<span id="cb168-5"><a href="#cb168-5" aria-hidden="true" tabindex="-1"></a>        model.train()</span>
<span id="cb168-6"><a href="#cb168-6" aria-hidden="true" tabindex="-1"></a>        <span class="co">#iterate through each batch</span></span>
<span id="cb168-7"><a href="#cb168-7" aria-hidden="true" tabindex="-1"></a>        <span class="cf">for</span> xb, yb <span class="kw">in</span> train_dl:</span>
<span id="cb168-8"><a href="#cb168-8" aria-hidden="true" tabindex="-1"></a>            preds <span class="op">=</span> model(xb)</span>
<span id="cb168-9"><a href="#cb168-9" aria-hidden="true" tabindex="-1"></a>            loss <span class="op">=</span> loss_func(preds, yb)</span>
<span id="cb168-10"><a href="#cb168-10" aria-hidden="true" tabindex="-1"></a>            loss.backward()</span>
<span id="cb168-11"><a href="#cb168-11" aria-hidden="true" tabindex="-1"></a>            opt.step()</span>
<span id="cb168-12"><a href="#cb168-12" aria-hidden="true" tabindex="-1"></a>            opt.zero_grad()</span>
<span id="cb168-13"><a href="#cb168-13" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb168-14"><a href="#cb168-14" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Set model to eval mode for validation</span></span>
<span id="cb168-15"><a href="#cb168-15" aria-hidden="true" tabindex="-1"></a>        model.<span class="bu">eval</span>()</span>
<span id="cb168-16"><a href="#cb168-16" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Run without grad calculations for validation (speed up model and use less memory)</span></span>
<span id="cb168-17"><a href="#cb168-17" aria-hidden="true" tabindex="-1"></a>        <span class="cf">with</span> torch.no_grad():</span>
<span id="cb168-18"><a href="#cb168-18" aria-hidden="true" tabindex="-1"></a>            <span class="co"># Reset the loss, accuracy and input count totals so that they can be used to sum values over the whole ds</span></span>
<span id="cb168-19"><a href="#cb168-19" aria-hidden="true" tabindex="-1"></a>            total_loss <span class="op">=</span> <span class="fl">0.</span><span class="op">;</span> total_acc<span class="op">=</span><span class="fl">0.</span><span class="op">;</span> total_count<span class="op">=</span><span class="dv">0</span></span>
<span id="cb168-20"><a href="#cb168-20" aria-hidden="true" tabindex="-1"></a>            <span class="cf">for</span> xb, yb <span class="kw">in</span> valid_dl:</span>
<span id="cb168-21"><a href="#cb168-21" aria-hidden="true" tabindex="-1"></a>                n_items <span class="op">=</span> <span class="bu">len</span>(yb)</span>
<span id="cb168-22"><a href="#cb168-22" aria-hidden="true" tabindex="-1"></a>                total_count <span class="op">+=</span> n_items</span>
<span id="cb168-23"><a href="#cb168-23" aria-hidden="true" tabindex="-1"></a>                preds <span class="op">=</span> model(xb)</span>
<span id="cb168-24"><a href="#cb168-24" aria-hidden="true" tabindex="-1"></a>                total_loss <span class="op">+=</span> loss_func(preds, yb)<span class="op">*</span>n_items</span>
<span id="cb168-25"><a href="#cb168-25" aria-hidden="true" tabindex="-1"></a>                total_acc <span class="op">+=</span> (torch.topk(preds, <span class="dv">1</span>)[<span class="dv">1</span>][:,<span class="dv">0</span>]<span class="op">==</span>yb).<span class="bu">sum</span>()</span>
<span id="cb168-26"><a href="#cb168-26" aria-hidden="true" tabindex="-1"></a>            <span class="bu">print</span>(<span class="ss">f"Epoch: </span><span class="sc">{</span>epoch<span class="sc">}</span><span class="ss">, loss: </span><span class="sc">{</span>total_loss<span class="op">/</span>total_count<span class="sc">}</span><span class="ss">, acc: </span><span class="sc">{</span>total_acc<span class="op">/</span>total_count<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb168-27"><a href="#cb168-27" aria-hidden="true" tabindex="-1"></a>    </span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell" data-execution_count="109">
<div class="sourceCode cell-code" id="cb169"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb169-1"><a href="#cb169-1" aria-hidden="true" tabindex="-1"></a>model,opt <span class="op">=</span> get_model_and_optimizer()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell" data-execution_count="110">
<div class="sourceCode cell-code" id="cb170"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb170-1"><a href="#cb170-1" aria-hidden="true" tabindex="-1"></a>fit(epochs<span class="op">=</span><span class="dv">3</span>, model<span class="op">=</span>model, loss_func<span class="op">=</span>loss_func, opt<span class="op">=</span>opt, train_dl<span class="op">=</span>train_dl, valid_dl<span class="op">=</span>valid_dl)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Epoch: 0, loss: 0.16384194791316986, acc: 0.9517999887466431
Epoch: 1, loss: 0.11577688157558441, acc: 0.963699996471405
Epoch: 2, loss: 0.11353033781051636, acc: 0.9666000008583069</code></pre>
</div>
</div>
<p>Finally create the dataloader using a function and then simplify the whole training process to three lines</p>
<div class="cell" data-execution_count="111">
<div class="sourceCode cell-code" id="cb172"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb172-1"><a href="#cb172-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> get_data_loaderers(train_ds, valid_ds, bs):</span>
<span id="cb172-2"><a href="#cb172-2" aria-hidden="true" tabindex="-1"></a>    train_dl <span class="op">=</span> DataLoader(train_ds, batch_size<span class="op">=</span>bs, shuffle<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb172-3"><a href="#cb172-3" aria-hidden="true" tabindex="-1"></a>    valid_ds <span class="op">=</span> DataLoader(valid_ds, batch_size<span class="op">=</span>bs, shuffle<span class="op">=</span><span class="va">False</span>)</span>
<span id="cb172-4"><a href="#cb172-4" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> train_dl, valid_dl</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell" data-execution_count="112">
<div class="sourceCode cell-code" id="cb173"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb173-1"><a href="#cb173-1" aria-hidden="true" tabindex="-1"></a>model, opt <span class="op">=</span> get_model_and_optimizer()</span>
<span id="cb173-2"><a href="#cb173-2" aria-hidden="true" tabindex="-1"></a>train_dl, valid_dl <span class="op">=</span> get_data_loaderers(train_ds, valid_ds, bs<span class="op">=</span>bs)</span>
<span id="cb173-3"><a href="#cb173-3" aria-hidden="true" tabindex="-1"></a>fit(epochs<span class="op">=</span><span class="dv">3</span>, model<span class="op">=</span>model, loss_func<span class="op">=</span>loss_func, opt<span class="op">=</span>opt, train_dl<span class="op">=</span>train_dl, valid_dl<span class="op">=</span>valid_dl)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Epoch: 0, loss: 0.20603491365909576, acc: 0.9343000054359436
Epoch: 1, loss: 0.20518435537815094, acc: 0.9363999962806702
Epoch: 2, loss: 0.1369418054819107, acc: 0.9598000049591064</code></pre>
</div>
</div>


</section>
</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const disableStylesheet = (stylesheets) => {
    for (let i=0; i < stylesheets.length; i++) {
      const stylesheet = stylesheets[i];
      stylesheet.rel = 'prefetch';
    }
  }
  const enableStylesheet = (stylesheets) => {
    for (let i=0; i < stylesheets.length; i++) {
      const stylesheet = stylesheets[i];
      stylesheet.rel = 'stylesheet';
    }
  }
  const manageTransitions = (selector, allowTransitions) => {
    const els = window.document.querySelectorAll(selector);
    for (let i=0; i < els.length; i++) {
      const el = els[i];
      if (allowTransitions) {
        el.classList.remove('notransition');
      } else {
        el.classList.add('notransition');
      }
    }
  }
  const toggleColorMode = (alternate) => {
    // Switch the stylesheets
    const alternateStylesheets = window.document.querySelectorAll('link.quarto-color-scheme.quarto-color-alternate');
    manageTransitions('#quarto-margin-sidebar .nav-link', false);
    if (alternate) {
      enableStylesheet(alternateStylesheets);
      for (const sheetNode of alternateStylesheets) {
        if (sheetNode.id === "quarto-bootstrap") {
          toggleBodyColorMode(sheetNode);
        }
      }
    } else {
      disableStylesheet(alternateStylesheets);
      toggleBodyColorPrimary();
    }
    manageTransitions('#quarto-margin-sidebar .nav-link', true);
    // Switch the toggles
    const toggles = window.document.querySelectorAll('.quarto-color-scheme-toggle');
    for (let i=0; i < toggles.length; i++) {
      const toggle = toggles[i];
      if (toggle) {
        if (alternate) {
          toggle.classList.add("alternate");     
        } else {
          toggle.classList.remove("alternate");
        }
      }
    }
    // Hack to workaround the fact that safari doesn't
    // properly recolor the scrollbar when toggling (#1455)
    if (navigator.userAgent.indexOf('Safari') > 0 && navigator.userAgent.indexOf('Chrome') == -1) {
      manageTransitions("body", false);
      window.scrollTo(0, 1);
      setTimeout(() => {
        window.scrollTo(0, 0);
        manageTransitions("body", true);
      }, 40);  
    }
  }
  const isFileUrl = () => { 
    return window.location.protocol === 'file:';
  }
  const hasAlternateSentinel = () => {  
    let styleSentinel = getColorSchemeSentinel();
    if (styleSentinel !== null) {
      return styleSentinel === "alternate";
    } else {
      return false;
    }
  }
  const setStyleSentinel = (alternate) => {
    const value = alternate ? "alternate" : "default";
    if (!isFileUrl()) {
      window.localStorage.setItem("quarto-color-scheme", value);
    } else {
      localAlternateSentinel = value;
    }
  }
  const getColorSchemeSentinel = () => {
    if (!isFileUrl()) {
      const storageValue = window.localStorage.getItem("quarto-color-scheme");
      return storageValue != null ? storageValue : localAlternateSentinel;
    } else {
      return localAlternateSentinel;
    }
  }
  let localAlternateSentinel = 'default';
  // Dark / light mode switch
  window.quartoToggleColorScheme = () => {
    // Read the current dark / light value 
    let toAlternate = !hasAlternateSentinel();
    toggleColorMode(toAlternate);
    setStyleSentinel(toAlternate);
  };
  // Ensure there is a toggle, if there isn't float one in the top right
  if (window.document.querySelector('.quarto-color-scheme-toggle') === null) {
    const a = window.document.createElement('a');
    a.classList.add('top-right');
    a.classList.add('quarto-color-scheme-toggle');
    a.href = "";
    a.onclick = function() { try { window.quartoToggleColorScheme(); } catch {} return false; };
    const i = window.document.createElement("i");
    i.classList.add('bi');
    a.appendChild(i);
    window.document.body.appendChild(a);
  }
  // Switch to dark mode if need be
  if (hasAlternateSentinel()) {
    toggleColorMode(true);
  } else {
    toggleColorMode(false);
  }
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const clipboard = new window.ClipboardJS('.code-copy-button', {
    target: function(trigger) {
      return trigger.previousElementSibling;
    }
  });
  clipboard.on('success', function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  });
  function tippyHover(el, contentFn) {
    const config = {
      allowHTML: true,
      content: contentFn,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start'
    };
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      return note.innerHTML;
    });
  }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
<script src="https://utteranc.es/client.js" repo="fromLittleAcorns/johnrichmond.github.io/" issue-term="pathname" theme="github-light" crossorigin="anonymous" async="">
</script>
</div> <!-- /content -->



</body></html>