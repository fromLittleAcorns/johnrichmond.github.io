<?xml version="1.0" encoding="UTF-8"?>
<rss  xmlns:atom="http://www.w3.org/2005/Atom" 
      xmlns:media="http://search.yahoo.com/mrss/" 
      xmlns:content="http://purl.org/rss/1.0/modules/content/" 
      xmlns:dc="http://purl.org/dc/elements/1.1/" 
      version="2.0">
<channel>
<title>John Richmond</title>
<link>https://fromLittleAcorns.github.io/john.richmond.github.io/blog.html</link>
<atom:link href="https://fromLittleAcorns.github.io/john.richmond.github.io/blog.xml" rel="self" type="application/rss+xml"/>
<description>7QN8N70N41&#39;s personal website</description>
<generator>quarto-1.2.269</generator>
<lastBuildDate>Fri, 11 Nov 2022 11:26:25 GMT</lastBuildDate>
<item>
  <title>Notebook to explore DiffEdit</title>
  <dc:creator>John Richmond</dc:creator>
  <link>https://fromLittleAcorns.github.io/john.richmond.github.io/posts/2022-11-10-StableDiffusion/2022-11-11-diffedit_explore.html</link>
  <description><![CDATA[ 



<section id="notebook-to-try-out-the-diffedit-methodology" class="level2">
<h2 class="anchored" data-anchor-id="notebook-to-try-out-the-diffedit-methodology">Notebook to try out the DiffEdit methodology</h2>
<p>This follows the paper: http://arxiv.org/abs/2210.11427</p>
<p>The first part of the notebook is setup to generate image masks based upon the differences in images generated by starting with the same noised image and denoising it with two different prompts, the first one the prompt that goes with the image, the second a prompt related to a “target” image, which is what it is desired to change some aspect of the image into.</p>
<p>The methodology in the paper is not very well described and so a few alternative approaches are considered</p>
<div class="cell" data-execution_count="1">
<div class="sourceCode cell-code" id="cb1" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb1-1"><span class="im" style="color: #00769E;">from</span> pathlib <span class="im" style="color: #00769E;">import</span> Path</span>
<span id="cb1-2"><span class="im" style="color: #00769E;">from</span> PIL <span class="im" style="color: #00769E;">import</span> Image</span>
<span id="cb1-3"><span class="im" style="color: #00769E;">from</span> tqdm.auto <span class="im" style="color: #00769E;">import</span> tqdm</span>
<span id="cb1-4"><span class="im" style="color: #00769E;">import</span> numpy <span class="im" style="color: #00769E;">as</span> np</span>
<span id="cb1-5"><span class="im" style="color: #00769E;">import</span> matplotlib.pyplot <span class="im" style="color: #00769E;">as</span> plt</span>
<span id="cb1-6"></span>
<span id="cb1-7"><span class="im" style="color: #00769E;">import</span> torch</span>
<span id="cb1-8"><span class="im" style="color: #00769E;">from</span> torchvision <span class="im" style="color: #00769E;">import</span> transforms <span class="im" style="color: #00769E;">as</span> tfms</span>
<span id="cb1-9"><span class="im" style="color: #00769E;">from</span> torch <span class="im" style="color: #00769E;">import</span> autocast</span>
<span id="cb1-10"></span>
<span id="cb1-11"><span class="im" style="color: #00769E;">from</span> diffusers <span class="im" style="color: #00769E;">import</span> DDIMScheduler, LMSDiscreteScheduler</span>
<span id="cb1-12"><span class="im" style="color: #00769E;">from</span> transformers <span class="im" style="color: #00769E;">import</span> CLIPTextModel, CLIPTokenizer</span>
<span id="cb1-13"><span class="im" style="color: #00769E;">from</span> diffusers <span class="im" style="color: #00769E;">import</span> AutoencoderKL, UNet2DConditionModel</span>
<span id="cb1-14"><span class="im" style="color: #00769E;">from</span> transformers <span class="im" style="color: #00769E;">import</span> logging</span></code></pre></div>
</div>
<div class="cell" data-execution_count="2">
<div class="sourceCode cell-code" id="cb2" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb2-1"><span class="co" style="color: #5E5E5E;">#!pip install accelerate</span></span></code></pre></div>
</div>
<div class="cell" data-execution_count="3">
<div class="sourceCode cell-code" id="cb3" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb3-1"><span class="co" style="color: #5E5E5E;"># Note that this step is helpful to avoid verbose warnings when loading the text encoder</span></span>
<span id="cb3-2">logging.set_verbosity_error()</span></code></pre></div>
</div>
<div class="cell" data-execution_count="4">
<div class="sourceCode cell-code" id="cb4" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb4-1"><span class="co" style="color: #5E5E5E;"># Set device</span></span>
<span id="cb4-2">torch_device <span class="op" style="color: #5E5E5E;">=</span> <span class="st" style="color: #20794D;">"cuda"</span> <span class="cf" style="color: #003B4F;">if</span> torch.cuda.is_available() <span class="cf" style="color: #003B4F;">else</span> <span class="st" style="color: #20794D;">"cpu"</span></span></code></pre></div>
</div>
<div class="cell" data-tags="[]" data-execution_count="5">
<div class="sourceCode cell-code" id="cb5" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb5-1"><span class="co" style="color: #5E5E5E;"># Load the tokenizer and text encoder</span></span>
<span id="cb5-2">tokenizer <span class="op" style="color: #5E5E5E;">=</span> CLIPTokenizer.from_pretrained(<span class="st" style="color: #20794D;">"openai/clip-vit-large-patch14"</span>, torch_dtype<span class="op" style="color: #5E5E5E;">=</span>torch.float16)</span>
<span id="cb5-3">text_encoder <span class="op" style="color: #5E5E5E;">=</span> CLIPTextModel.from_pretrained(<span class="st" style="color: #20794D;">"openai/clip-vit-large-patch14"</span>, torch_dtype<span class="op" style="color: #5E5E5E;">=</span>torch.float16).to(torch_device)</span></code></pre></div>
</div>
<div class="cell" data-execution_count="6">
<div class="sourceCode cell-code" id="cb6" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb6-1"><span class="co" style="color: #5E5E5E;"># Load the VAE and Unet</span></span>
<span id="cb6-2">vae <span class="op" style="color: #5E5E5E;">=</span> AutoencoderKL.from_pretrained(<span class="st" style="color: #20794D;">"stabilityai/sd-vae-ft-ema"</span>, torch_dtype<span class="op" style="color: #5E5E5E;">=</span>torch.float16).to(torch_device)</span>
<span id="cb6-3">unet <span class="op" style="color: #5E5E5E;">=</span> UNet2DConditionModel.from_pretrained(<span class="st" style="color: #20794D;">"CompVis/stable-diffusion-v1-4"</span>, subfolder<span class="op" style="color: #5E5E5E;">=</span><span class="st" style="color: #20794D;">"unet"</span>, torch_dtype<span class="op" style="color: #5E5E5E;">=</span>torch.float16).to(torch_device)</span></code></pre></div>
</div>
<div class="cell" data-execution_count="7">
<div class="sourceCode cell-code" id="cb7" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb7-1"><span class="co" style="color: #5E5E5E;"># Create a DDIM scheduler</span></span>
<span id="cb7-2">ddim_sched <span class="op" style="color: #5E5E5E;">=</span> DDIMScheduler(beta_start<span class="op" style="color: #5E5E5E;">=</span><span class="fl" style="color: #AD0000;">0.00085</span>, </span>
<span id="cb7-3">                                    beta_end<span class="op" style="color: #5E5E5E;">=</span><span class="fl" style="color: #AD0000;">0.012</span>, </span>
<span id="cb7-4">                                    beta_schedule<span class="op" style="color: #5E5E5E;">=</span><span class="st" style="color: #20794D;">'scaled_linear'</span>, </span>
<span id="cb7-5">                                    clip_sample<span class="op" style="color: #5E5E5E;">=</span><span class="va" style="color: #111111;">False</span>, </span>
<span id="cb7-6">                                    set_alpha_to_one<span class="op" style="color: #5E5E5E;">=</span><span class="va" style="color: #111111;">False</span>)</span></code></pre></div>
</div>
<div class="cell" data-execution_count="8">
<div class="sourceCode cell-code" id="cb8" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb8-1"><span class="co" style="color: #5E5E5E;"># Create a LMS scheduler</span></span>
<span id="cb8-2">scheduler <span class="op" style="color: #5E5E5E;">=</span> LMSDiscreteScheduler(beta_start<span class="op" style="color: #5E5E5E;">=</span><span class="fl" style="color: #AD0000;">0.00085</span>, beta_end<span class="op" style="color: #5E5E5E;">=</span><span class="fl" style="color: #AD0000;">0.012</span>, beta_schedule<span class="op" style="color: #5E5E5E;">=</span><span class="st" style="color: #20794D;">"scaled_linear"</span>, num_train_timesteps<span class="op" style="color: #5E5E5E;">=</span><span class="dv" style="color: #AD0000;">1000</span>)</span></code></pre></div>
</div>
</section>
<section id="add-functions" class="level2">
<h2 class="anchored" data-anchor-id="add-functions">Add Functions</h2>
<div class="cell" data-execution_count="9">
<div class="sourceCode cell-code" id="cb9" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb9-1"><span class="kw" style="color: #003B4F;">def</span> prompt_to_embedding(prompt: <span class="bu" style="color: null;">str</span>, torch_device):</span>
<span id="cb9-2">    text_input <span class="op" style="color: #5E5E5E;">=</span> tokenizer(prompt, padding<span class="op" style="color: #5E5E5E;">=</span><span class="st" style="color: #20794D;">"max_length"</span>, max_length<span class="op" style="color: #5E5E5E;">=</span>tokenizer.model_max_length, truncation<span class="op" style="color: #5E5E5E;">=</span><span class="va" style="color: #111111;">True</span>, return_tensors<span class="op" style="color: #5E5E5E;">=</span><span class="st" style="color: #20794D;">"pt"</span>)</span>
<span id="cb9-3">    <span class="cf" style="color: #003B4F;">with</span> torch.no_grad():</span>
<span id="cb9-4">        embeddings <span class="op" style="color: #5E5E5E;">=</span> text_encoder(text_input.input_ids.to(torch_device))[<span class="dv" style="color: #AD0000;">0</span>]</span>
<span id="cb9-5">    <span class="cf" style="color: #003B4F;">return</span> embeddings</span></code></pre></div>
</div>
<div class="cell" data-execution_count="10">
<div class="sourceCode cell-code" id="cb10" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb10-1"><span class="kw" style="color: #003B4F;">def</span> pil_to_latent(input_im):</span>
<span id="cb10-2">    <span class="co" style="color: #5E5E5E;"># Single image -&gt; single latent in a batch (so size 1, 4, 64, 64)</span></span>
<span id="cb10-3">    <span class="cf" style="color: #003B4F;">with</span> torch.no_grad():</span>
<span id="cb10-4">        latent <span class="op" style="color: #5E5E5E;">=</span> vae.encode(tfms.ToTensor()(input_im).unsqueeze(<span class="dv" style="color: #AD0000;">0</span>).half().to(torch_device)<span class="op" style="color: #5E5E5E;">*</span><span class="dv" style="color: #AD0000;">2</span><span class="op" style="color: #5E5E5E;">-</span><span class="dv" style="color: #AD0000;">1</span>) <span class="co" style="color: #5E5E5E;"># Note scaling</span></span>
<span id="cb10-5">    <span class="cf" style="color: #003B4F;">return</span> <span class="fl" style="color: #AD0000;">0.18215</span> <span class="op" style="color: #5E5E5E;">*</span> latent.latent_dist.sample()</span></code></pre></div>
</div>
<div class="cell" data-execution_count="11">
<div class="sourceCode cell-code" id="cb11" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb11-1"><span class="kw" style="color: #003B4F;">def</span> latents_to_array(latents):</span>
<span id="cb11-2">    latents <span class="op" style="color: #5E5E5E;">=</span> <span class="dv" style="color: #AD0000;">1</span> <span class="op" style="color: #5E5E5E;">/</span> <span class="fl" style="color: #AD0000;">0.18215</span> <span class="op" style="color: #5E5E5E;">*</span> latents</span>
<span id="cb11-3">    <span class="cf" style="color: #003B4F;">with</span> torch.no_grad():</span>
<span id="cb11-4">        image <span class="op" style="color: #5E5E5E;">=</span> vae.decode(latents).sample</span>
<span id="cb11-5"></span>
<span id="cb11-6">    <span class="co" style="color: #5E5E5E;"># Create image array</span></span>
<span id="cb11-7">    image <span class="op" style="color: #5E5E5E;">=</span> (image <span class="op" style="color: #5E5E5E;">/</span> <span class="dv" style="color: #AD0000;">2</span> <span class="op" style="color: #5E5E5E;">+</span> <span class="fl" style="color: #AD0000;">0.5</span>).clamp(<span class="dv" style="color: #AD0000;">0</span>, <span class="dv" style="color: #AD0000;">1</span>)</span>
<span id="cb11-8">    image <span class="op" style="color: #5E5E5E;">=</span> image.detach().cpu().permute(<span class="dv" style="color: #AD0000;">0</span>, <span class="dv" style="color: #AD0000;">2</span>, <span class="dv" style="color: #AD0000;">3</span>, <span class="dv" style="color: #AD0000;">1</span>).numpy()</span>
<span id="cb11-9">    images <span class="op" style="color: #5E5E5E;">=</span> (image <span class="op" style="color: #5E5E5E;">*</span> <span class="dv" style="color: #AD0000;">255</span>).<span class="bu" style="color: null;">round</span>().astype(<span class="st" style="color: #20794D;">"uint8"</span>)</span>
<span id="cb11-10">    <span class="co" style="color: #5E5E5E;"># At this point, this is a single-item array of image data, so return only the item </span></span>
<span id="cb11-11">    <span class="co" style="color: #5E5E5E;"># to remove the extra diemension from the returned data</span></span>
<span id="cb11-12">    <span class="cf" style="color: #003B4F;">return</span> images[<span class="dv" style="color: #AD0000;">0</span>]</span></code></pre></div>
</div>
<div class="cell" data-execution_count="12">
<div class="sourceCode cell-code" id="cb12" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb12-1"><span class="kw" style="color: #003B4F;">def</span> latents_to_pil(latents):</span>
<span id="cb12-2">    <span class="co" style="color: #5E5E5E;"># bath of latents -&gt; list of images</span></span>
<span id="cb12-3">    image <span class="op" style="color: #5E5E5E;">=</span> latents_to_array(latents)</span>
<span id="cb12-4">    pil_imagea <span class="op" style="color: #5E5E5E;">=</span> Image.fromarray(image)</span>
<span id="cb12-5">    <span class="cf" style="color: #003B4F;">return</span> pil_imagea</span></code></pre></div>
</div>
<div class="cell" data-execution_count="13">
<div class="sourceCode cell-code" id="cb13" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb13-1"><span class="kw" style="color: #003B4F;">def</span> show_latents(latents):</span>
<span id="cb13-2">    fig, axs <span class="op" style="color: #5E5E5E;">=</span> plt.subplots(<span class="dv" style="color: #AD0000;">1</span>, <span class="dv" style="color: #AD0000;">4</span>, figsize<span class="op" style="color: #5E5E5E;">=</span>(<span class="dv" style="color: #AD0000;">16</span>, <span class="dv" style="color: #AD0000;">4</span>))</span>
<span id="cb13-3">    <span class="cf" style="color: #003B4F;">for</span> c <span class="kw" style="color: #003B4F;">in</span> <span class="bu" style="color: null;">range</span>(<span class="dv" style="color: #AD0000;">4</span>):</span>
<span id="cb13-4">        axs[c].imshow(latents[<span class="dv" style="color: #AD0000;">0</span>][c].cpu(), cmap<span class="op" style="color: #5E5E5E;">=</span><span class="st" style="color: #20794D;">'Greys'</span>)</span>
<span id="cb13-5">        axs[c].axis(<span class="st" style="color: #20794D;">'off'</span>)</span></code></pre></div>
</div>
<div class="cell" data-execution_count="14">
<div class="sourceCode cell-code" id="cb14" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb14-1"><span class="kw" style="color: #003B4F;">def</span> load_image(path_to_image, size):</span>
<span id="cb14-2">    path_to_img <span class="op" style="color: #5E5E5E;">=</span> Path(path_to_image)</span>
<span id="cb14-3">    <span class="cf" style="color: #003B4F;">assert</span> path_to_img.is_file(), <span class="ss" style="color: #20794D;">f"No file found </span><span class="sc" style="color: #5E5E5E;">{</span>path_to_image<span class="sc" style="color: #5E5E5E;">}</span><span class="ss" style="color: #20794D;">"</span></span>
<span id="cb14-4">    image <span class="op" style="color: #5E5E5E;">=</span> Image.<span class="bu" style="color: null;">open</span>(path_to_img).convert(<span class="st" style="color: #20794D;">'RGB'</span>)</span>
<span id="cb14-5">    <span class="cf" style="color: #003B4F;">return</span> image</span></code></pre></div>
</div>
<div class="cell" data-execution_count="15">
<div class="sourceCode cell-code" id="cb15" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb15-1"><span class="kw" style="color: #003B4F;">def</span> denoising_loop(latents, text_emb, scheduler, g<span class="op" style="color: #5E5E5E;">=</span><span class="fl" style="color: #AD0000;">7.5</span>, strength<span class="op" style="color: #5E5E5E;">=</span><span class="fl" style="color: #AD0000;">0.5</span>, steps<span class="op" style="color: #5E5E5E;">=</span><span class="dv" style="color: #AD0000;">50</span>, dim<span class="op" style="color: #5E5E5E;">=</span><span class="dv" style="color: #AD0000;">512</span>, start_step<span class="op" style="color: #5E5E5E;">=</span><span class="dv" style="color: #AD0000;">10</span>, torch_device<span class="op" style="color: #5E5E5E;">=</span><span class="st" style="color: #20794D;">"cuda"</span>):</span>
<span id="cb15-2">    <span class="cf" style="color: #003B4F;">with</span> autocast(torch_device):</span>
<span id="cb15-3">        noise_preds <span class="op" style="color: #5E5E5E;">=</span> torch.tensor([], device<span class="op" style="color: #5E5E5E;">=</span>torch_device)</span>
<span id="cb15-4">        <span class="cf" style="color: #003B4F;">for</span> i, t <span class="kw" style="color: #003B4F;">in</span> <span class="bu" style="color: null;">enumerate</span>(scheduler.timesteps):</span>
<span id="cb15-5">            <span class="cf" style="color: #003B4F;">if</span> i <span class="op" style="color: #5E5E5E;">&gt;</span> start_step:</span>
<span id="cb15-6">                <span class="co" style="color: #5E5E5E;">#print(f"step: {i}")</span></span>
<span id="cb15-7">                latent_model_input <span class="op" style="color: #5E5E5E;">=</span> torch.cat([latents] <span class="op" style="color: #5E5E5E;">*</span> <span class="dv" style="color: #AD0000;">2</span>)</span>
<span id="cb15-8">                latent_model_input <span class="op" style="color: #5E5E5E;">=</span> scheduler.scale_model_input(latent_model_input, t)</span>
<span id="cb15-9">                <span class="cf" style="color: #003B4F;">with</span> torch.no_grad():</span>
<span id="cb15-10">                    noise_u,noise_t <span class="op" style="color: #5E5E5E;">=</span> unet(latent_model_input, t, encoder_hidden_states<span class="op" style="color: #5E5E5E;">=</span>text_emb).sample.chunk(<span class="dv" style="color: #AD0000;">2</span>)</span>
<span id="cb15-11">                noise_pred <span class="op" style="color: #5E5E5E;">=</span> noise_u <span class="op" style="color: #5E5E5E;">+</span> g<span class="op" style="color: #5E5E5E;">*</span>(noise_t <span class="op" style="color: #5E5E5E;">-</span> noise_u)</span>
<span id="cb15-12">                noise_preds <span class="op" style="color: #5E5E5E;">=</span> torch.concat([noise_preds, noise_pred])</span>
<span id="cb15-13">                latents <span class="op" style="color: #5E5E5E;">=</span> scheduler.step(noise_pred, t, latents).prev_sample</span>
<span id="cb15-14">        <span class="cf" style="color: #003B4F;">return</span> latents, noise_preds</span></code></pre></div>
</div>
<div class="cell" data-execution_count="16">
<div class="sourceCode cell-code" id="cb16" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb16-1"><span class="kw" style="color: #003B4F;">def</span> show_image(image, seed<span class="op" style="color: #5E5E5E;">=</span><span class="va" style="color: #111111;">None</span>, scale_by<span class="op" style="color: #5E5E5E;">=</span><span class="fl" style="color: #AD0000;">0.5</span>):</span>
<span id="cb16-2">    <span class="cf" style="color: #003B4F;">if</span> seed <span class="kw" style="color: #003B4F;">is</span> <span class="kw" style="color: #003B4F;">not</span> <span class="va" style="color: #111111;">None</span>:</span>
<span id="cb16-3">        <span class="bu" style="color: null;">print</span>(<span class="ss" style="color: #20794D;">f'Seed: </span><span class="sc" style="color: #5E5E5E;">{</span>seed<span class="sc" style="color: #5E5E5E;">}</span><span class="ss" style="color: #20794D;">'</span>)</span>
<span id="cb16-4">    <span class="cf" style="color: #003B4F;">return</span> image.resize(((<span class="bu" style="color: null;">int</span>)(image.width <span class="op" style="color: #5E5E5E;">*</span> scale_by), (<span class="bu" style="color: null;">int</span>)(image.height <span class="op" style="color: #5E5E5E;">*</span> scale_by)))</span></code></pre></div>
</div>
<div class="cell" data-execution_count="17">
<div class="sourceCode cell-code" id="cb17" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb17-1"><span class="kw" style="color: #003B4F;">def</span> add_noise_to_image(latents, seed, scheduler, start_step):</span>
<span id="cb17-2">    torch.manual_seed(seed)</span>
<span id="cb17-3">    noise <span class="op" style="color: #5E5E5E;">=</span> torch.randn_like(latents)</span>
<span id="cb17-4">    noised_latents <span class="op" style="color: #5E5E5E;">=</span> scheduler.add_noise(</span>
<span id="cb17-5">        original_samples<span class="op" style="color: #5E5E5E;">=</span>latents, </span>
<span id="cb17-6">        noise<span class="op" style="color: #5E5E5E;">=</span>noise, </span>
<span id="cb17-7">        timesteps<span class="op" style="color: #5E5E5E;">=</span>torch.tensor([scheduler.timesteps[start_step]]))</span>
<span id="cb17-8">    <span class="cf" style="color: #003B4F;">return</span> noised_latents</span></code></pre></div>
</div>
<div class="cell" data-execution_count="18">
<div class="sourceCode cell-code" id="cb18" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb18-1"><span class="kw" style="color: #003B4F;">def</span> show_images(nrows, ncols, images, titles<span class="op" style="color: #5E5E5E;">=</span>[], figsize<span class="op" style="color: #5E5E5E;">=</span>(<span class="dv" style="color: #AD0000;">16</span>, <span class="dv" style="color: #AD0000;">5</span>)):</span>
<span id="cb18-2">    num_axes <span class="op" style="color: #5E5E5E;">=</span> nrows<span class="op" style="color: #5E5E5E;">*</span>ncols</span>
<span id="cb18-3">    num_images <span class="op" style="color: #5E5E5E;">=</span> <span class="bu" style="color: null;">len</span>(images)</span>
<span id="cb18-4">    num_titles <span class="op" style="color: #5E5E5E;">=</span> <span class="bu" style="color: null;">len</span>(titles)</span>
<span id="cb18-5">    fig, axs <span class="op" style="color: #5E5E5E;">=</span> plt.subplots(nrows, ncols, figsize<span class="op" style="color: #5E5E5E;">=</span>figsize)</span>
<span id="cb18-6">    flt_ax <span class="op" style="color: #5E5E5E;">=</span> axs.flat</span>
<span id="cb18-7">    <span class="cf" style="color: #003B4F;">for</span> c <span class="kw" style="color: #003B4F;">in</span> <span class="bu" style="color: null;">range</span>(num_axes):</span>
<span id="cb18-8">        <span class="cf" style="color: #003B4F;">if</span> c <span class="op" style="color: #5E5E5E;">==</span> num_images: <span class="cf" style="color: #003B4F;">break</span></span>
<span id="cb18-9">        flt_ax[c].imshow(images[c])</span>
<span id="cb18-10">        flt_ax[c].axis(<span class="st" style="color: #20794D;">'off'</span>)</span>
<span id="cb18-11">        <span class="cf" style="color: #003B4F;">if</span> c <span class="op" style="color: #5E5E5E;">&lt;</span> num_titles:</span>
<span id="cb18-12">            flt_ax[c].set_title(titles[c])</span></code></pre></div>
</div>
</section>
<section id="define-parameters-for-analysis" class="level2">
<h2 class="anchored" data-anchor-id="define-parameters-for-analysis">Define parameters for analysis</h2>
<div class="cell" data-execution_count="19">
<div class="sourceCode cell-code" id="cb19" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb19-1">resolution <span class="op" style="color: #5E5E5E;">=</span> <span class="dv" style="color: #AD0000;">512</span></span>
<span id="cb19-2">def_steps <span class="op" style="color: #5E5E5E;">=</span> <span class="dv" style="color: #AD0000;">70</span></span>
<span id="cb19-3">def_g <span class="op" style="color: #5E5E5E;">=</span> <span class="fl" style="color: #AD0000;">7.5</span></span>
<span id="cb19-4">def_strength <span class="op" style="color: #5E5E5E;">=</span> <span class="fl" style="color: #AD0000;">0.5</span></span>
<span id="cb19-5">def_sch <span class="op" style="color: #5E5E5E;">=</span> scheduler</span>
<span id="cb19-6">start_step <span class="op" style="color: #5E5E5E;">=</span> <span class="dv" style="color: #AD0000;">20</span></span></code></pre></div>
</div>
</section>
<section id="load-base-image-and-create-latents" class="level2">
<h2 class="anchored" data-anchor-id="load-base-image-and-create-latents">Load base image and create latents</h2>
<div class="cell" data-execution_count="20">
<div class="sourceCode cell-code" id="cb20" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb20-1">path_to_image <span class="op" style="color: #5E5E5E;">=</span> <span class="st" style="color: #20794D;">"/home/images/horse_1_512.jpg"</span></span>
<span id="cb20-2">image <span class="op" style="color: #5E5E5E;">=</span> load_image(path_to_image, resolution)</span>
<span id="cb20-3">latents <span class="op" style="color: #5E5E5E;">=</span> pil_to_latent(image)</span></code></pre></div>
</div>
<div class="cell" data-execution_count="21">
<div class="sourceCode cell-code" id="cb21" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb21-1"><span class="co" style="color: #5E5E5E;"># show the base image</span></span>
<span id="cb21-2">show_image(image)</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="21">
<p><img src="https://fromLittleAcorns.github.io/john.richmond.github.io/posts/2022-11-10-StableDiffusion/2022-11-11-diffedit_explore_files/figure-html/cell-22-output-1.png" class="img-fluid"></p>
</div>
</div>
<div class="cell" data-execution_count="22">
<div class="sourceCode cell-code" id="cb22" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb22-1"><span class="co" style="color: #5E5E5E;"># Plot the latents</span></span>
<span id="cb22-2">show_latents(latents)</span></code></pre></div>
<div class="cell-output cell-output-display">
<p><img src="https://fromLittleAcorns.github.io/john.richmond.github.io/posts/2022-11-10-StableDiffusion/2022-11-11-diffedit_explore_files/figure-html/cell-23-output-1.png" class="img-fluid"></p>
</div>
</div>
</section>
<section id="define-prompts-and-create-embeddings" class="level2">
<h2 class="anchored" data-anchor-id="define-prompts-and-create-embeddings">Define Prompts and create embeddings</h2>
<div class="cell" data-execution_count="23">
<div class="sourceCode cell-code" id="cb23" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb23-1"><span class="co" style="color: #5E5E5E;">#base_prompt = "A horse running on grass under a cloudy blue sky"</span></span>
<span id="cb23-2"><span class="co" style="color: #5E5E5E;">#target_prompt = "A zebra running on grass under a cloudy blue sky"</span></span>
<span id="cb23-3">base_prompt <span class="op" style="color: #5E5E5E;">=</span> <span class="st" style="color: #20794D;">"A horse"</span></span>
<span id="cb23-4">target_prompt <span class="op" style="color: #5E5E5E;">=</span> <span class="st" style="color: #20794D;">"Zebra"</span></span>
<span id="cb23-5">unguided_prompt <span class="op" style="color: #5E5E5E;">=</span> [<span class="st" style="color: #20794D;">""</span>]</span></code></pre></div>
</div>
<div class="cell" data-execution_count="24">
<div class="sourceCode cell-code" id="cb24" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb24-1">base_prompt_emb <span class="op" style="color: #5E5E5E;">=</span> prompt_to_embedding(base_prompt, torch_device)</span>
<span id="cb24-2">target_prompt_emb <span class="op" style="color: #5E5E5E;">=</span> prompt_to_embedding(target_prompt, torch_device)</span>
<span id="cb24-3">unguided_prompt <span class="op" style="color: #5E5E5E;">=</span> prompt_to_embedding(unguided_prompt, torch_device)</span></code></pre></div>
</div>
<div class="cell" data-execution_count="25">
<div class="sourceCode cell-code" id="cb25" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb25-1">base_emb_pair <span class="op" style="color: #5E5E5E;">=</span> torch.concat([unguided_prompt, base_prompt_emb])</span>
<span id="cb25-2">target_emb_pair <span class="op" style="color: #5E5E5E;">=</span> torch.concat([unguided_prompt, target_prompt_emb])</span></code></pre></div>
</div>
</section>
<section id="set-inference-timesteps" class="level2">
<h2 class="anchored" data-anchor-id="set-inference-timesteps">Set inference timesteps</h2>
<div class="cell" data-execution_count="26">
<div class="sourceCode cell-code" id="cb26" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb26-1"><span class="kw" style="color: #003B4F;">def</span> prepare_scheduler_noise_image_and_denoise(latents, text_emb, steps, start_step, scheduler, seed, g, dim, device):</span>
<span id="cb26-2">    timesteps <span class="op" style="color: #5E5E5E;">=</span> scheduler.set_timesteps(steps)</span>
<span id="cb26-3">    strength<span class="op" style="color: #5E5E5E;">=</span><span class="fl" style="color: #AD0000;">0.5</span></span>
<span id="cb26-4">    noised_latents <span class="op" style="color: #5E5E5E;">=</span> add_noise_to_image(latents, seed, scheduler, start_step)</span>
<span id="cb26-5">    dn_latents, noise <span class="op" style="color: #5E5E5E;">=</span> denoising_loop(noised_latents, text_emb<span class="op" style="color: #5E5E5E;">=</span>text_emb, scheduler<span class="op" style="color: #5E5E5E;">=</span>scheduler, g<span class="op" style="color: #5E5E5E;">=</span>g, strength<span class="op" style="color: #5E5E5E;">=</span>strength, steps<span class="op" style="color: #5E5E5E;">=</span><span class="dv" style="color: #AD0000;">70</span>, </span>
<span id="cb26-6">                                           dim<span class="op" style="color: #5E5E5E;">=</span>dim, start_step<span class="op" style="color: #5E5E5E;">=</span>start_step, torch_device<span class="op" style="color: #5E5E5E;">=</span>device)</span>
<span id="cb26-7">    <span class="cf" style="color: #003B4F;">return</span> dn_latents, noise</span>
<span id="cb26-8">    </span></code></pre></div>
</div>
<div class="cell" data-execution_count="27">
<div class="sourceCode cell-code" id="cb27" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb27-1">dn_base, noise_base <span class="op" style="color: #5E5E5E;">=</span> prepare_scheduler_noise_image_and_denoise(latents, </span>
<span id="cb27-2">                                                                text_emb<span class="op" style="color: #5E5E5E;">=</span>base_emb_pair, </span>
<span id="cb27-3">                                                                steps<span class="op" style="color: #5E5E5E;">=</span>def_steps, </span>
<span id="cb27-4">                                                                start_step<span class="op" style="color: #5E5E5E;">=</span><span class="dv" style="color: #AD0000;">30</span>, </span>
<span id="cb27-5">                                                                scheduler<span class="op" style="color: #5E5E5E;">=</span>def_sch, </span>
<span id="cb27-6">                                                                seed<span class="op" style="color: #5E5E5E;">=</span><span class="dv" style="color: #AD0000;">100</span>, </span>
<span id="cb27-7">                                                                g<span class="op" style="color: #5E5E5E;">=</span><span class="fl" style="color: #AD0000;">7.5</span>,</span>
<span id="cb27-8">                                                                dim<span class="op" style="color: #5E5E5E;">=</span>resolution, </span>
<span id="cb27-9">                                                                device<span class="op" style="color: #5E5E5E;">=</span>torch_device)</span></code></pre></div>
<div class="cell-output cell-output-stderr">
<pre><code>/opt/conda/lib/python3.8/site-packages/diffusers/schedulers/scheduling_lms_discrete.py:155: IntegrationWarning: The maximum number of subdivisions (50) has been achieved.
  If increasing the limit yields no improvement it is advised to analyze 
  the integrand in order to determine the difficulties.  If the position of a 
  local difficulty can be determined (singularity, discontinuity) one will 
  probably gain from splitting up the interval and calling the integrator 
  on the subranges.  Perhaps a special-purpose integrator should be used.
  integrated_coeff = integrate.quad(lms_derivative, self.sigmas[t], self.sigmas[t + 1], epsrel=1e-4)[0]</code></pre>
</div>
</div>
<div class="cell" data-execution_count="28">
<div class="sourceCode cell-code" id="cb29" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb29-1">latents_to_pil(dn_base)</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="28">
<p><img src="https://fromLittleAcorns.github.io/john.richmond.github.io/posts/2022-11-10-StableDiffusion/2022-11-11-diffedit_explore_files/figure-html/cell-29-output-1.png" class="img-fluid"></p>
</div>
</div>
<div class="cell" data-execution_count="29">
<div class="sourceCode cell-code" id="cb30" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb30-1">dn_target, noise_target <span class="op" style="color: #5E5E5E;">=</span> prepare_scheduler_noise_image_and_denoise(latents, </span>
<span id="cb30-2">                                                                text_emb<span class="op" style="color: #5E5E5E;">=</span>target_emb_pair, </span>
<span id="cb30-3">                                                                steps<span class="op" style="color: #5E5E5E;">=</span>def_steps, </span>
<span id="cb30-4">                                                                start_step<span class="op" style="color: #5E5E5E;">=</span><span class="dv" style="color: #AD0000;">30</span>, </span>
<span id="cb30-5">                                                                scheduler<span class="op" style="color: #5E5E5E;">=</span>def_sch, </span>
<span id="cb30-6">                                                                seed<span class="op" style="color: #5E5E5E;">=</span><span class="dv" style="color: #AD0000;">100</span>, </span>
<span id="cb30-7">                                                                g<span class="op" style="color: #5E5E5E;">=</span><span class="fl" style="color: #AD0000;">7.5</span>,</span>
<span id="cb30-8">                                                                dim<span class="op" style="color: #5E5E5E;">=</span>resolution, </span>
<span id="cb30-9">                                                                device<span class="op" style="color: #5E5E5E;">=</span>torch_device)</span></code></pre></div>
</div>
<div class="cell" data-execution_count="30">
<div class="sourceCode cell-code" id="cb31" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb31-1">latents_to_pil(dn_target)</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="30">
<p><img src="https://fromLittleAcorns.github.io/john.richmond.github.io/posts/2022-11-10-StableDiffusion/2022-11-11-diffedit_explore_files/figure-html/cell-31-output-1.png" class="img-fluid"></p>
</div>
</div>
<div class="cell" data-execution_count="31">
<div class="sourceCode cell-code" id="cb32" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb32-1">show_images(<span class="dv" style="color: #AD0000;">1</span>, <span class="dv" style="color: #AD0000;">3</span> , [np.asarray(image), latents_to_array(dn_base), latents_to_array(dn_target)],</span>
<span id="cb32-2">           [<span class="st" style="color: #20794D;">"Original Image"</span>, <span class="st" style="color: #20794D;">"Denoised original"</span>, <span class="st" style="color: #20794D;">"Denoised Zebra"</span>, <span class="st" style="color: #20794D;">"Denoised Zebra with mask"</span>])</span></code></pre></div>
<div class="cell-output cell-output-display">
<p><img src="https://fromLittleAcorns.github.io/john.richmond.github.io/posts/2022-11-10-StableDiffusion/2022-11-11-diffedit_explore_files/figure-html/cell-32-output-1.png" class="img-fluid"></p>
</div>
</div>
<div class="cell" data-execution_count="32">
<div class="sourceCode cell-code" id="cb33" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb33-1">orig_img <span class="op" style="color: #5E5E5E;">=</span> np.asarray(image)</span>
<span id="cb33-2">orig_img.shape</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="32">
<pre><code>(512, 515, 3)</code></pre>
</div>
</div>
<div class="cell" data-execution_count="33">
<div class="sourceCode cell-code" id="cb35" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb35-1">noise_base.shape</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="33">
<pre><code>torch.Size([39, 4, 64, 64])</code></pre>
</div>
</div>
<div class="cell" data-execution_count="34">
<div class="sourceCode cell-code" id="cb37" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb37-1">diff_noises <span class="op" style="color: #5E5E5E;">=</span> (noise_base <span class="op" style="color: #5E5E5E;">-</span> noise_target).mean(<span class="dv" style="color: #AD0000;">0</span>, keepdim<span class="op" style="color: #5E5E5E;">=</span><span class="va" style="color: #111111;">True</span>)</span></code></pre></div>
</div>
<div class="cell" data-execution_count="35">
<div class="sourceCode cell-code" id="cb38" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb38-1">diff_noises.shape</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="35">
<pre><code>torch.Size([1, 4, 64, 64])</code></pre>
</div>
</div>
<div class="cell" data-execution_count="36">
<div class="sourceCode cell-code" id="cb40" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb40-1">diff_noise_normed <span class="op" style="color: #5E5E5E;">=</span> (diff_noises <span class="op" style="color: #5E5E5E;">-</span> diff_noises.<span class="bu" style="color: null;">min</span>())<span class="op" style="color: #5E5E5E;">/</span>(diff_noises <span class="op" style="color: #5E5E5E;">-</span> diff_noises.<span class="bu" style="color: null;">min</span>()).<span class="bu" style="color: null;">max</span>()</span></code></pre></div>
</div>
<div class="cell" data-execution_count="37">
<div class="sourceCode cell-code" id="cb41" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb41-1">diff_noise_normed.shape</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="37">
<pre><code>torch.Size([1, 4, 64, 64])</code></pre>
</div>
</div>
<div class="cell" data-execution_count="38">
<div class="sourceCode cell-code" id="cb43" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb43-1">show_latents(diff_noise_normed)</span></code></pre></div>
<div class="cell-output cell-output-display">
<p><img src="https://fromLittleAcorns.github.io/john.richmond.github.io/posts/2022-11-10-StableDiffusion/2022-11-11-diffedit_explore_files/figure-html/cell-39-output-1.png" class="img-fluid"></p>
</div>
</div>
<div class="cell" data-execution_count="39">
<div class="sourceCode cell-code" id="cb44" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb44-1">diff_noise_normed.<span class="bu" style="color: null;">min</span>(), diff_noise_normed.<span class="bu" style="color: null;">max</span>(), diff_noise_normed.std(), diff_noise_normed.mean()</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="39">
<pre><code>(tensor(0., device='cuda:0'),
 tensor(1., device='cuda:0'),
 tensor(0.0744, device='cuda:0'),
 tensor(0.5083, device='cuda:0'))</code></pre>
</div>
</div>
<div class="cell" data-execution_count="40">
<div class="sourceCode cell-code" id="cb46" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb46-1">mask <span class="op" style="color: #5E5E5E;">=</span> ((diff_noise_normed<span class="op" style="color: #5E5E5E;">-</span><span class="fl" style="color: #AD0000;">0.5</span>).<span class="bu" style="color: null;">abs</span>()<span class="op" style="color: #5E5E5E;">+</span><span class="fl" style="color: #AD0000;">0.5</span>).mean(dim<span class="op" style="color: #5E5E5E;">=</span><span class="dv" style="color: #AD0000;">1</span>).squeeze().cpu()</span></code></pre></div>
</div>
<div class="cell" data-execution_count="41">
<div class="sourceCode cell-code" id="cb47" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb47-1"><span class="im" style="color: #00769E;">import</span> cv2</span></code></pre></div>
</div>
<div class="cell" data-execution_count="42">
<div class="sourceCode cell-code" id="cb48" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb48-1"><span class="kw" style="color: #003B4F;">def</span> extract_channel_mask(img, do_inverse<span class="op" style="color: #5E5E5E;">=</span><span class="va" style="color: #111111;">False</span>):</span>
<span id="cb48-2">    kernel <span class="op" style="color: #5E5E5E;">=</span> np.ones((<span class="dv" style="color: #AD0000;">3</span>,<span class="dv" style="color: #AD0000;">3</span>),np.uint8)</span>
<span id="cb48-3">    img <span class="op" style="color: #5E5E5E;">=</span> (img<span class="op" style="color: #5E5E5E;">*</span><span class="dv" style="color: #AD0000;">255</span>).squeeze().cpu().to(torch.uint8).numpy()</span>
<span id="cb48-4">    <span class="cf" style="color: #003B4F;">if</span> do_inverse:</span>
<span id="cb48-5">        ret2,img2 <span class="op" style="color: #5E5E5E;">=</span> cv2.threshold(img,<span class="dv" style="color: #AD0000;">0</span>,<span class="dv" style="color: #AD0000;">255</span>,cv2.THRESH_BINARY_INV<span class="op" style="color: #5E5E5E;">+</span>cv2.THRESH_OTSU)</span>
<span id="cb48-6">    <span class="cf" style="color: #003B4F;">else</span>:</span>
<span id="cb48-7">        ret2,img2 <span class="op" style="color: #5E5E5E;">=</span> cv2.threshold(img,<span class="dv" style="color: #AD0000;">0</span>,<span class="dv" style="color: #AD0000;">255</span>,cv2.THRESH_BINARY<span class="op" style="color: #5E5E5E;">+</span>cv2.THRESH_OTSU)</span>
<span id="cb48-8">    opening <span class="op" style="color: #5E5E5E;">=</span> cv2.dilate(img2, kernel)</span>
<span id="cb48-9">    <span class="cf" style="color: #003B4F;">return</span> opening</span></code></pre></div>
</div>
<div class="cell" data-execution_count="44">
<div class="sourceCode cell-code" id="cb49" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb49-1">show_images(<span class="dv" style="color: #AD0000;">2</span>, <span class="dv" style="color: #AD0000;">1</span>, [mask, extract_channel_mask(mask, do_inverse<span class="op" style="color: #5E5E5E;">=</span><span class="va" style="color: #111111;">False</span>)])</span></code></pre></div>
<div class="cell-output cell-output-display">
<p><img src="https://fromLittleAcorns.github.io/john.richmond.github.io/posts/2022-11-10-StableDiffusion/2022-11-11-diffedit_explore_files/figure-html/cell-44-output-1.png" class="img-fluid"></p>
</div>
</div>
</section>
<section id="now-need-to-apply-the-mask-to-the-generated-zebra-image-and-then-run-the-decode-function" class="level2">
<h2 class="anchored" data-anchor-id="now-need-to-apply-the-mask-to-the-generated-zebra-image-and-then-run-the-decode-function">Now need to apply the mask to the generated zebra image and then run the decode function</h2>
<div class="cell" data-execution_count="45">
<div class="sourceCode cell-code" id="cb50" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb50-1">binary_mask <span class="op" style="color: #5E5E5E;">=</span> torch.tensor(extract_channel_mask(mask, do_inverse<span class="op" style="color: #5E5E5E;">=</span><span class="va" style="color: #111111;">False</span>)).<span class="bu" style="color: null;">bool</span>()</span></code></pre></div>
</div>
<div class="cell" data-execution_count="46">
<div class="sourceCode cell-code" id="cb51" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb51-1"><span class="kw" style="color: #003B4F;">def</span> apply_mask_to_latents(original_latents, new_latents, mask):</span>
<span id="cb51-2">    comp_lat <span class="op" style="color: #5E5E5E;">=</span> torch.where(mask, new_latents.cpu(), original_latents.cpu())</span>
<span id="cb51-3">    <span class="cf" style="color: #003B4F;">return</span> comp_lat</span></code></pre></div>
</div>
<div class="cell" data-execution_count="47">
<div class="sourceCode cell-code" id="cb52" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb52-1">final_latents <span class="op" style="color: #5E5E5E;">=</span> apply_mask_to_latents(dn_base, dn_target, binary_mask)</span></code></pre></div>
</div>
<div class="cell" data-execution_count="48">
<div class="sourceCode cell-code" id="cb53" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb53-1">latents_to_pil(final_latents.to(torch_device))</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="48">
<p><img src="https://fromLittleAcorns.github.io/john.richmond.github.io/posts/2022-11-10-StableDiffusion/2022-11-11-diffedit_explore_files/figure-html/cell-48-output-1.png" class="img-fluid"></p>
</div>
</div>
<div class="cell" data-execution_count="49">
<div class="sourceCode cell-code" id="cb54" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb54-1">show_images(<span class="dv" style="color: #AD0000;">2</span>, <span class="dv" style="color: #AD0000;">2</span>, [np.asarray(image), latents_to_array(dn_base), latents_to_array(dn_target), latents_to_array(final_latents.to(torch_device))],</span>
<span id="cb54-2">           [<span class="st" style="color: #20794D;">"Original Image"</span>, <span class="st" style="color: #20794D;">"Denoised original"</span>, <span class="st" style="color: #20794D;">"Denoised Zebra"</span>, <span class="st" style="color: #20794D;">"Denoised Zebra with mask"</span>], figsize<span class="op" style="color: #5E5E5E;">=</span>(<span class="dv" style="color: #AD0000;">10</span>,<span class="dv" style="color: #AD0000;">10</span>))</span></code></pre></div>
<div class="cell-output cell-output-display">
<p><img src="https://fromLittleAcorns.github.io/john.richmond.github.io/posts/2022-11-10-StableDiffusion/2022-11-11-diffedit_explore_files/figure-html/cell-49-output-1.png" class="img-fluid"></p>
</div>
</div>
<p>In this case the final masked image is almost identical to that of the unmasked image since the background generated by the denoising process had almost no differene. In other cases this could clearly be more extreme. The issue of course would be that the mask would need to be carefully blended to facilitate a smooth merge.</p>
<p>Overall it seems to me that this is an approach that has very limited application an in many ways it is better to avoid using the mask</p>


</section>

 ]]></description>
  <guid>https://fromLittleAcorns.github.io/john.richmond.github.io/posts/2022-11-10-StableDiffusion/2022-11-11-diffedit_explore.html</guid>
  <pubDate>Fri, 11 Nov 2022 11:26:25 GMT</pubDate>
</item>
</channel>
</rss>
